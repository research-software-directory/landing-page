[{"primaryKey": {"id": "3d-e-chem-knime-kripodb", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2019-01-31T08:28:20Z", "brandName": "KNIME node for Kripo", "bullets": "* For cheminformaticans who want to do structure-based protein binding site comparison and bioisosteric replacement for ligand design\n* It makes the Kripo Python library available in the KNIME workflow platform as workflow nodes.\n* Kripo encodes the interactions of protein and bound ligand also known as a pharmacophore into a fingerprint, the fingerprints can be compared to each other to find similar pharmacophores\n* The Kripo software is open source while most other similar software is commercial or requires registration", "conceptDOI": "10.5281/zenodo.597262", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://www.knime.com/3d-e-chem-nodes-for-knime", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-kripodb"]}, "isFeatured": false, "isPublished": true, "license": ["GPL-3.0"], "programmingLanguage": ["Java", "Python"], "readMore": null, "shortStatement": "A node for the KNIME workflow systems that allows you to compare different binding sites in proteins with each other.", "slug": "knime-kripodb", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"id": "BBEY84IC", "collection": "mention"}}, {"foreignKey": {"id": "SJRUXGD3", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "sverhoeven"}, {"primaryKey": {"id": "3d-e-chem-knime-pharmacophore", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-11-27T10:43:37Z", "brandName": "KNIME Pharmacophore", "bullets": "* For cheminformations who are working with pharmacphores in KNIME workflows.\n* Adds pharmacophore data type to KNIME\n* Adds nodes to read, write and align pharmacophores\n", "conceptDOI": "10.5281/zenodo.997332", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "s.verhoeven", "collection": "person"}, "isContactPerson": true}], "getStartedURL": "https://github.com/3D-e-Chem/knime-pharmacophore", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-pharmacophore"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": "A pharmacophore is an abstract description of molecular features that are necessary for molecular recognition of a ligand by a biological macromolecule. This plugin for the KNIME workflow system adds the Pharmacophore (Phar) data type to KNIME, and adds nodes to read, write, and manipulate pharmacophores inside KNIME. It includes the [KNIME Silicos-it](https://www.research-software.nl/software/3d-e-chem-knime-silicos-it), [Kripo pharmacophore retrieval](https://www.research-software.nl/software/3d-e-chem-knime-kripodb) and [molviewer pharmacophore viewer](https://www.research-software.nl/software/knime-molviewer) nodes. \n\n\n", "shortStatement": "A plugin for the KNIME workflow system that adds a Pharmacophore data type and nodes to read, write, and align them.", "slug": "3d-e-chem-knime-pharmacophore", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "3d-e-chem-knime-plants", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-11-27T13:56:38Z", "brandName": "KNIME PLANTS", "bullets": "* For cheminformaticians who want to combine protein-ligand docking with other KNIME workflow steps\n* Makes it possible to generate a PLANTS config file, run the PLANTS executable and ingest the PLANTS output from a KNIME workflow\n* The KNIME nodes come bundled with a PLANTS executable, so it does not have to be installed by each user separately\n* Used in workflows to perform an all-versus-all docking of all ligand-protein complexes of the Kinase and GPRC family in the protein data bank\n", "conceptDOI": "10.5281/zenodo.997272", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/knime-plants#installation", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-plants"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "A node for the KNIME workflow system that allows you to use the PLANTS protein-ligand docking algorithm.", "slug": "3d-e-chem-knime-plants", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "3d-e-chem-knime-python-node-archetype", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-05-24T08:11:40Z", "brandName": "KNIME Python node archetype", "bullets": "* Similar to KNIME node archetype, but gives utilities to call Python library in a node\n* For KNIME node developers who like to have  quick start and automated builds\n* Generates a project skeleton that contains all you need to develop your own KNIME nodes\n* Automates tests and deploying the node to an update site\n* Includes dependency management and test coverage\n* Used to create all KNIME Python nodes in the 3D-e-Chem project", "conceptDOI": "10.5281/zenodo.597226", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/knime-python-node-archetype", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-python-node-archetype"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Java", "Python"], "readMore": null, "shortStatement": "Want to write your own KNIME node wrapping a Python library. Then use the KNIME Python node archetype to generate a node skeleton repository with sample code", "slug": "3d-e-chem-knime-python-node-archetype", "tags": ["Workflow technologies", "Big data"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "knime-archetype", "collection": "software"}}], "mentions": [], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "sverhoeven"}, {"primaryKey": {"id": "3d-e-chem-knime-python-wrapper", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-03-16T12:50:45Z", "brandName": "KNIME Python wrapper", "bullets": "* Provides an abstract classes for KNIME node developers to quickly develop KNIME nodes which call Python code\n* KNIME provides Python nodes which have an text editor as configuration, this software provides a way to provide your own configuration dialog\n* Can check if certain Python libraries have been installed \n* Will make fields on the configuration dialog available inside the Python code\n* Can make warning message generated in Python code visible in KNIME platform", "conceptDOI": "10.5281/zenodo.597238", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/knime-python-wrapper", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-python-wrapper"]}, "isFeatured": false, "isPublished": true, "license": ["GPL-3.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "If you are developing a KNIME node which calls some Python code, then the KNIME Python wrapper can help you.", "slug": "3d-e-chem-knime-python-wrapper", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "3d-e-chem-knime-silicos-it", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-11-27T10:49:41Z", "brandName": "KNIME Silicos-it nodes", "bullets": "* For cheminformaticians that want to use the Silicos-it software in the KNIME workflow platform\n* A thin wrapper around the Silicos-it software, the node can be configured using dialog instead of command line arguments\n* The Silicos-it shape-it is used to align molecules based on shape and align-it is used to align molecules based on their pharmacophore \n* The Silicos-it binaries come bundled with the KNIME node installation so you don't need to download and compile the Silicos-it software yourself", "conceptDOI": "10.5281/zenodo.597793", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "s.verhoeven", "collection": "person"}, "isContactPerson": true}, {"affiliations": [{"foreignKey": {"id": "vua", "collection": "organization"}}], "foreignKey": {"id": "5ae85e6f0bd42f30d8877d43", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/3D-e-Chem/knime-silicos-it", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-silicos-it"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "A node for the KNIME workflow systems that allows you to use the Silicos-it software to filter or align molecules.", "slug": "3d-e-chem-knime-silicos-it", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "3d-e-chem-vm", "collection": "software"}}], "mentions": [{"foreignKey": {"id": "DHQZYQRG", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "3d-e-chem-knime-sygma", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-05-23T15:43:06Z", "brandName": "KNIME SYGMa node", "bullets": "- FIXME\n- FIXME\n- FIXME\n", "conceptDOI": "10.5281/zenodo.1033752", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/knime-sygma", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-sygma"]}, "isFeatured": false, "isPublished": false, "license": ["GPL-3.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "KNIME node for molecule metabolization.", "slug": "3d-e-chem-knime-sygma", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": []}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "3d-e-chem-kripodb", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-05-24T08:30:34Z", "brandName": "Kripo", "bullets": "* For cheminformaticans who want to do structure-based protein binding site comparison and bioisosteric replacement for ligand design\n* Kripo stands for Key Representation of Interaction in POckets\n* Kripo encodes the interactions of protein and bound ligand also known as a pharmacophore into a fingerprint, the fingerprints can be compared to each other to find similar pharmacophores\n* The Kripo software is open source while most other similar software is commercial or requires registration", "conceptDOI": "10.5281/zenodo.597178", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "vua", "collection": "organization"}}], "foreignKey": {"id": "5ae85e6f0bd42f30d8877d43", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/3D-e-Chem/kripo", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/kripodb", "https://github.com/3D-e-Chem/kripo"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0", "GPL-3.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "If you want to compare different binding sites in proteins with each other, then Kripo is the tool for you", "slug": "kripo", "tags": ["Workflow technologies", "Optimized data handling"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "3d-e-chem-vm", "collection": "software"}}], "mentions": [], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "sverhoeven"}, {"primaryKey": {"id": "3d-e-chem-sygma", "collection": "software"}, "createdAt": "2017-11-14T13:13:32Z", "updatedAt": "2018-03-15T14:56:02Z", "brandName": "SyGMa", "bullets": "- Predict human metabolites for a given (drug) molecule by:\n- Systematically applying chemical rules for phase 1 and phase 2 biotransformations\n- Ranking of predicted metabolites based on empirical success rates for each rule", "conceptDOI": "10.5281/zenodo.1043306", "contributors": [{"foreignKey": {"collection": "person", "id": "l.ridder"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://sygma.readthedocs.io", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/sygma"]}, "isFeatured": false, "isPublished": true, "license": ["GPL-3.0"], "programmingLanguage": ["Python"], "readMore": "This tool is a reimplementation of the metabolic rules outlined in:\n\n [Ridder, L., & Wagener, M. (2008) SyGMa: combining expert knowledge and empirical scoring in the prediction of metabolites. ChemMedChem, 3(5), 821-832.](http://onlinelibrary.wiley.com/doi/10.1002/cmdc.200700312/full)", "shortStatement": "SyGMa provides fast and lightweight predictions of human metabolites to support discovery scientists design better and safer drugs  ", "slug": "3d-e-chem-sygma", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "QGIC4HKR"}}, {"foreignKey": {"collection": "mention", "id": "J73MRLY9"}}], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "3d-e-chem-vm", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T13:50:09Z", "brandName": "3D-e-Chem Virtual Machine", "bullets": "* Gives cheminformaticians that don't want to install lots of software a single command to get all the software they need to perform ligand binding site comparisons and GPCR research\n* The VM contains a fully functional cheminformatics infrastructure\n* The VM was used in several workshops, giving all participants the same environment and quick start\n", "conceptDOI": "10.5281/zenodo.594559", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d33"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/3D-e-Chem-VM#usage", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/3D-e-Chem-VM"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["YAML"], "readMore": null, "shortStatement": "A freely available Virtual Machine encompassing tools, databases, and workflows for cheminformaticians, including new resources developed for ligand binding site comparisons and GPCR research.", "slug": "3d-e-chem-vm", "tags": ["Workflow technologies", "Inter-operability & linked data"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "BBEY84IC"}}, {"foreignKey": {"collection": "mention", "id": "QGIC4HKR"}}, {"foreignKey": {"collection": "mention", "id": "Z8T3H5NG"}}], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "aa-alert-amber-setup", "collection": "software"}, "createdAt": "2017-11-16T15:29:15Z", "updatedAt": "2018-05-28T14:21:59Z", "brandName": "AMBER_setup", "bullets": "TODO add a bullet list", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "a.sclocco"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.attema"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/AA-ALERT/AMBER_setup", "repositoryURLs": {"github": []}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Shell scripts"], "readMore": null, "shortStatement": "TODO add a short statement", "slug": "aa-alert-amber-setup", "tags": [], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "amber", "collection": "software"}}, {"foreignKey": {"id": "dedispersion", "collection": "software"}}, {"foreignKey": {"id": "astrodata", "collection": "software"}}], "mentions": [], "projects": [{"foreignKey": {"id": "aa-alert", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "astron", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "ahn-pointcloud-viewer-ws", "collection": "software"}, "createdAt": "2017-11-16T14:06:53Z", "updatedAt": "2018-11-27T14:19:36Z", "brandName": "AHN point cloud viewer web service", "bullets": "* Able to handle data sets of billions of points\n* Allows for the extraction of points from areas of interest to the user\n* Provides tools for measurement", "conceptDOI": "10.5281/zenodo.909307", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/ahn-pointcloud-viewer", "repositoryURLs": {"github": ["https://github.com/NLeSC/ahn-pointcloud-viewer-ws"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript"], "readMore": "This web application was developed in collaboration with Markus Schutz, the developer of potree. \nIf you want to set up your own web application with this kind of data, we highly recommend Massive-PotreeConverter, which you can find on this site.", "shortStatement": "A web service to serve large point cloud data efficiently using octrees. ", "slug": "ahn-pointcloud-viewer-ws", "tags": ["Visualization", "Big data"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "6WURICLY"}}], "projects": [{"foreignKey": {"id": "massive-point-clouds-for-esciences", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "tudelft", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "ahn2webviewer", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T14:19:29Z", "brandName": "AHN2 pointcloud viewer", "bullets": "* For all users interested in geo-data that need an intuitive interface to browse this data and / or extract parts of it for other uses, this webGL Pointcloud viewer is the best of the bunch, because it is the only one out there capable of displaying 640 billion points. Geo-scientists, archeologists, spatial planners, biologists or environmentalists performing exploratory analysis of massive LiDAR data sets ('point clouds') composed of billions of points using Potree-powered web-based viewer. \n* Tools to enable interactive web-based visual analytics on massive point clouds. \n* These are the only tools that enable interactive web-based visual analytics on massive point clouds. No other web-based tool can display a point cloud this massive. 640 billion points.", "conceptDOI": "10.5281/zenodo.910448", "contributors": [{"foreignKey": {"collection": "person", "id": "m.vanmeersbergen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://ahn2.pointclouds.nl", "repositoryURLs": {"github": ["https://github.com/NLeSC/ahn-pointcloud-viewer"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript"], "readMore": null, "shortStatement": "A web application able to visualize the AHN2 point cloud data of the Netherlands. ", "slug": "ahn2webviewer", "tags": ["Visualization", "Big data", "Real time data analysis"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "massivepotreeconverter", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "6WURICLY"}}], "projects": [{"foreignKey": {"id": "massive-point-clouds-for-esciences", "collection": "project"}}, {"foreignKey": {"id": "mapping-the-via-appia-in-3d", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "fugro", "collection": "organization"}}, {"foreignKey": {"id": "potree", "collection": "organization"}}, {"foreignKey": {"id": "tudelft", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "allelic-variation-explorer", "collection": "software"}, "createdAt": "2017-11-14T13:13:32Z", "updatedAt": "2018-11-26T10:17:18Z", "brandName": "Allelic Variation Explorer", "bullets": "* It provides a genome browser with a track where the samples which have the same SNPs are clustered together, it can be used by bioinformations to explain why certain samples have the same phenotype\n* It takes variants of a large number of samples and for the requested genomic range it performs clustering and visualizes the clusters\n* the clustering is done quick and on the fly \n* the reference genome, gene and feature tracks are rendered from static files, so you don't need any application server just a static web server", "conceptDOI": "10.5281/zenodo.1145887", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "m.kuzak"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/nlesc-ave/ave-rest-service", "repositoryURLs": {"github": ["https://github.com/nlesc-ave/ave-rest-service"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "JavaScript"], "readMore": null, "shortStatement": "If you are studying how single nucleotide polymorphisms are clustered in genomic samples, then the Allelic Variation Explorer can help you visualize them.", "slug": "allelic-variation-explorer", "tags": ["Visualization"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "the-virtual-laboratory-for-plant-breeding", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "wur", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "amber", "collection": "software"}, "createdAt": "2017-11-16T14:22:26Z", "updatedAt": "2018-05-28T14:22:09Z", "brandName": "AMBER", "bullets": "* Real-time radio transient searching pipeline\n* High-performance and portability", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "a.sclocco"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.attema"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/AA-ALERT/AMBER", "repositoryURLs": {"github": ["https://github.com/AA-ALERT/AMBER"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["C++", "OpenCL"], "readMore": null, "shortStatement": "A real-time pipeline to search for Fast Radio Bursts and other transient radio sources.", "slug": "amber", "tags": ["Real time data analysis", "Big data", "High performance computing", "GPU"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "dedispersion", "collection": "software"}}, {"foreignKey": {"id": "astrodata", "collection": "software"}}], "mentions": [], "projects": [{"foreignKey": {"id": "aa-alert", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "astron", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "amuse", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-09-27T08:15:52Z", "brandName": "AMUSE", "bullets": "* provides a homogeneous environment to design astrophysical simulations used by students and researchers\n* couples different simulation codes in a Python environment to be run locally or distributed\n* provides a very easy way to solve astronomical problems that involve complicated physical interactions \n* used for more than 40 scientific papers and PhD theses", "conceptDOI": "10.5281/zenodo.1435860", "contributors": [{"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d34"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "leiden-university", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d35"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "leiden-university", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d36"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "cbc4a82b-e0fc-4564-837e-785a9b99416c", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "i.pelupessy"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "n.drost"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://www.amusecode.org/", "repositoryURLs": {"github": ["https://github.com/amusecode/amuse"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "Java", "C++", "C", "CUDA", "OpenCL"], "readMore": null, "shortStatement": "Combine existing numerical codes in an easy to use Python framework. With AMUSE you can simulate objects such as star clusters, proto-planetary disks and galaxies.", "slug": "amuse", "tags": ["Multi-scale & multi model simulations", "High performance computing", "Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "abc-muse", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "leiden-university", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "arena-crowds", "collection": "software"}, "createdAt": "2017-11-14T13:30:36Z", "updatedAt": "2018-05-24T09:08:19Z", "brandName": "Arena-Crowds", "bullets": "TODO fill me with something proper", "conceptDOI": "10.5281/zenodo.592479", "contributors": [{"foreignKey": {"collection": "person", "id": "s.georgievska"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/ArenA-Crowds/Crowds", "repositoryURLs": {"github": ["https://github.com/ArenA-Crowds/Crowds"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "TODO fill me with something proper", "slug": "arena-crowds", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "S795D8IQ"}}], "projects": [], "organizations": []}, "createdBy": "Unknown", "updatedBy": "sverhoeven"}, {"primaryKey": {"id": "astrodata", "collection": "software"}, "createdAt": "2017-11-16T15:28:10Z", "updatedAt": "2018-05-24T09:10:43Z", "brandName": "AstroData", "bullets": "TODO fill me with something proper", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "a.sclocco"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.attema"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/AA-ALERT/AstroData", "repositoryURLs": {"github": ["https://github.com/AA-ALERT/AstroData"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["C++"], "readMore": null, "shortStatement": "TODO fill me with something proper", "slug": "astrodata", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "aa-alert", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "astron", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "sverhoeven"}, {"primaryKey": {"id": "beyond-the-book", "collection": "software"}, "createdAt": "2017-11-16T13:37:30Z", "updatedAt": "2018-09-27T11:23:07Z", "brandName": "Beyond the book", "bullets": "* Provides humanities scholars with a tool to mine Wikipedia.\n* Mine Wikipedia revision history.\n* Ease of use for humanities scholars\n* Can be used as a proxy to measure the cultural bias from a country towards a specific topic\n", "conceptDOI": "10.5281/zenodo.1436372", "contributors": [{"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/c-martinez/BeyondTheBook/blob/master/PageContributionByCountry.ipynb", "repositoryURLs": {"github": ["https://github.com/c-martinez/BeyondTheBook"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "The book translation market is a topic of interest in literary studies, but the reasons why a book is selected for translation are not well understood. The \"Beyond the Book\" project investigates whether web resources like Wikipedia can be used to establish the level of cultural bias. This work describes the eScience tools used to estimate the cultural appeal of a book: semantic linking is used to identify key words in the text of the book, and afterwards the revision information from corresponding Wikipedia articles is examined to identify countries that generated a more than average amount of contributions to those articles. Comparison between the number of contributions from two countries on the same set of articles may show with which knowledge the contributors are familiar. We assume a lack of contributions from a country may indicate a gap in the knowledge of readers from that country. We assume that a book dealing with that concept could be more exotic and therefore more appealing for certain readers, while others are therefore less interested in the book. An indication of the 'level of exoticness' thus could help a reader/publisher to decide to read/translate the book or not. Experimental results are presented for four selected books from a set of 564 books written in Dutch or translated into Dutch, assessing their potential appeal for a Canadian audience. A qualitative assessment of quantitative results provides insight into named entities that may indicate a high/low cultural bias towards a book.", "shortStatement": "Measure the number of contributions to Wikipedia entries from individuals from different counties as a measure of cultural bias.", "slug": "beyond-the-book", "tags": ["Text analysis & natural language processing"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "DU63YN7N"}}, {"foreignKey": {"collection": "mention", "id": "RSTQW429"}}, {"foreignKey": {"collection": "mention", "id": "RLMJJ7JW"}}], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "cartodb-docker-image", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-05-24T09:17:29Z", "brandName": "CartoDB Docker image", "bullets": "* For people that want to run their own CartoDB instance\n* A fully functional version of https://carto.com/ running in a Docker container\n* CartoDB is a complicated and big software stack. The whole stack is contained inside this Docker image", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://hub.docker.com/r/sverhoeven/cartodb/", "repositoryURLs": {"github": ["https://github.com/sverhoeven/docker-cartodb"]}, "isFeatured": false, "isPublished": false, "license": ["BSD-3-Clause"], "programmingLanguage": ["Python", "Ruby", "C++"], "readMore": null, "shortStatement": "This docker container provides a fully working CartoDB development solution without the installation hassle.", "slug": "cartodb-docker-image", "tags": ["Visualization"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "eecology", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "uva", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "sverhoeven"}, {"primaryKey": {"id": "case-law-app", "collection": "software"}, "createdAt": "2017-11-14T12:48:04Z", "updatedAt": "2018-03-06T16:14:07Z", "brandName": "Case Law App", "bullets": "* Provides a graphical representation of Dutch case law for researchers\n* Allows exploring the network of citations between court decisions\n* Contains an example network about employer liability\n", "conceptDOI": "10.5281/zenodo.596839", "contributors": [{"foreignKey": {"collection": "person", "id": "d.vankuppevelt"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://nlesc.github.io/case-law-app/", "repositoryURLs": {"github": ["https://github.com/NLeSC/case-law-app"]}, "isFeatured": true, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript"], "readMore": "The law is a text that describes what a person or legal entity can and cannot\ndo. However, the law is somewhat open to interpretation. This interpretation is\ndone by judges whenever a case is brought to court. Over time, the outcome of\nindividual cases build what is called _case law_.\n\nBecause consistency is crucial for the fair application of the law, cases often\nreference other cases: if the reasoning behind a ruling in one case also applies\nto another case, then the ruling should be the same. To warrant consistency it\nis thus paramount that any relevant rulings from previous cases are identified.\nConventionally, both the justice department and the defense depend on legal\nexperts to make this identification when preparing a case. However, court\nrulings are often difficult to understand, there is only limited time available,\nand even experts are not aware of all cases that may be relevant.\n\nTo help mitigate this situation, the Netherlands eScience Center worked together\nwith Maastricht University to develop an interactive visualization that assists\nthe legal community at large (prosecutors, judges, lawyers, legal aids, but also\nresearchers and students) in analyzing case law.\n\nThe visualization has been implemented as follows. The collective of cases that\ntogether make up case law can be thought of as a network, or _graph_. Each node\nin the graph represents a case, while the edges represent references to other\ncases. The graph is represented visually to make it easy for a non-technical\nuser to discover which cases are related. By using metrics from graph theory,\nsuch as _in-degree_, _out-degree_, _betweenness_, etc., the nodes in the graph\ncan be annotated with additional information. The additional information helps\na researcher quickly assess a node's importance.", "shortStatement": "Web application for exploring the citation network of Dutch court decisions.", "slug": "case-law-app", "tags": ["Visualization", "Text analysis & natural language processing"], "testimonials": [{"affiliation": "Professor of Private Law, Maastricht University", "person": "Gijs van Dijck", "text": "It\u2019s quite amazing to see how, thanks to this tool, a student can, in some ways, outperform the expert."}], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "CZSGY275"}}, {"foreignKey": {"collection": "mention", "id": "LIR4RZP7"}}, {"foreignKey": {"collection": "mention", "id": "7X4NKPAQ"}}, {"foreignKey": {"collection": "mention", "id": "3UWNT2WV"}}, {"foreignKey": {"collection": "mention", "id": "BIGZT2AQ"}}], "projects": [{"foreignKey": {"id": "case-law-analytics", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "maastricht-university", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "caselawanalytics", "collection": "software"}, "createdAt": "2017-11-14T12:48:04Z", "updatedAt": "2018-03-06T16:14:19Z", "brandName": "caselawnet", "bullets": "* Search tool for legal experts or students, interested in in network analysis\n* Search publicly available Dutch judgments on keywords and download the result as a network\n* The exported network can be visualized in the [Case Law App](https://www.research-software.nl/software/case-law-app)\n* Provides both a graphical user interface and a python package", "conceptDOI": "10.5281/zenodo.832894", "contributors": [{"foreignKey": {"collection": "person", "id": "d.vankuppevelt"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/caselawanalytics/CaseLawAnalytics", "repositoryURLs": {"github": ["https://github.com/caselawanalytics/CaseLawAnalytics"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "The law is a text that describes what a person or legal entity can and cannot\ndo. However, the law is somewhat open to interpretation. This interpretation is\ndone by judges whenever a case is brought to court. Over time, the outcome of\nindividual cases build what is called _case law_.\n\nBecause consistency is crucial for the fair application of the law, cases often\nreference other cases: if the reasoning behind a ruling in one case also applies\nto another case, then the ruling should be the same. To warrant consistency it\nis thus paramount that any relevant rulings from previous cases are identified.\nConventionally, both the justice department and the defense depend on legal\nexperts to make this identification when preparing a case. However, court\nrulings are often difficult to understand, there is only limited time available,\nand even experts are not aware of all cases that may be relevant.\n\nTo help mitigate this situation, the Netherlands eScience Center worked together\nwith Maastricht University to develop an [interactive visualization](https://www.research-software.nl/software/case-law-app) that assists\nthe legal community at large (prosecutors, judges, lawyers, legal aids, but also\nresearchers and students) in analyzing case law. \n\nTo analyze a specific topic or theme in the law, a collection of law cases first need to be represented as a network or _graph_.  Each node\nin the graph represents a case, while the edges represent references to other cases. The caselawnet tool is basically a search machine, that retrieves the cases related to a search term, as well as the citations between those cases. The network can be downloaded and directly used in the visualization.", "shortStatement": "Caselawnet constructs citation networks from collections of Dutch case law.", "slug": "caselawanalytics", "tags": ["Big data"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "case-law-analytics", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "maastricht-university", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "cclustera", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-24T09:21:06Z", "brandName": "CClusTera", "bullets": "TODO fill me with something proper", "conceptDOI": "10.5281/zenodo.60993", "contributors": [{"foreignKey": {"collection": "person", "id": "s.georgievska"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/sonjageorgievska/CClusTera", "repositoryURLs": {"github": ["https://github.com/sonjageorgievska/CClusTera"]}, "isFeatured": false, "isPublished": false, "license": ["AFL-3.0"], "programmingLanguage": ["JavaScript", "Python", "C++"], "readMore": null, "shortStatement": "A 3D web tool for interactive visualization of hierarchically clustered large datasets", "slug": "cclustera", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "sverhoeven"}, {"primaryKey": {"id": "cerise", "collection": "software"}, "createdAt": "2017-11-14T13:13:32Z", "updatedAt": "2018-05-24T09:25:10Z", "brandName": "Cerise", "bullets": "* Lets you make running workflows on HPC resources easy\n* You provides users with a CWL API, they combine tools into a workflow\n* Installs software, accepts workflows, stages files, executes\n* REST/CWL/Docker/Python client", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "l.veen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://cerise.readthedocs.io/en/latest/introduction.html", "repositoryURLs": {"github": ["https://github.com/MD-Studio/cerise"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "Cerise is a generic service for running CWL workflows on compute resources (i.e. clusters, supercomputers, and simply remote machines). It tries to offer a consistent environment for workflows, so that a workflow sent to resource A will work unchanged on resource B as well.\n\nTo achieve this, and to offer a bit of safety and perhaps security, Cerise does not allow running arbitrary CWL command line tools. Instead, it expects the user to submit a workflow document that refers to predefined steps built into the service.\n\nDefining these steps, and adding them to the service, is called specialising the service. A specialisation of Cerise is always specific to a project (which determines which steps are available and what inputs and outputs they have), and to a compute resource (which determines how they are implemented). Thus, two workflows sent to two different specialisations to the same project, but to different compute resources, should give the same result (assuming the calculation is deterministic!).", "shortStatement": "Cerise is a service for running  CWL workflows on HPC resources. You add software, tool descriptions, and connection information, then your user runs workflows  whenever they want.", "slug": "cerise", "tags": ["Optimized data handling", "High performance computing", "Workflow technologies"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "xenon", "collection": "software"}}], "mentions": [], "projects": [{"foreignKey": {"id": "enhancing-protein-drug-binding-prediction", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "sverhoeven"}, {"primaryKey": {"id": "cesium-ncwms", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T14:36:45Z", "brandName": "Cesium-ncWMS", "bullets": "* A Web-based 3D globe visualization for NetCDF data\n* Allows analysis of points of interest by clicking spots on the globe\n* Works in collaboration with ncWMS to translate NetCDF data into images", "conceptDOI": "10.5281/zenodo.60031", "contributors": [{"foreignKey": {"collection": "person", "id": "m.vanmeersbergen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "n.drost"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/eWaterCycle/Cesium-NcWMS", "repositoryURLs": {"github": ["https://github.com/eWaterCycle/Cesium-NcWMS"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript", "Java"], "readMore": "Cesium (cesiumjs.org) based visualization using ncWMS to serve NetCDF data and D3 (d3js.org) to display graphs.\nA live running version of this software can be found here: http://forecast.ewatercycle.org", "shortStatement": "Web Application that visualizes data stored in the NetCDF format on a globe.", "slug": "cesium-ncwms", "tags": ["Visualization"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "ewatercycle", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "chemical-analytics-platform", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-26T10:27:01Z", "brandName": "Chemical Analytics Platform", "bullets": "* The virtual machine contains a fully functional cheminformatics infrastructure like RDKit and PyMol\n* The virtual machine was used in several workshops, giving all participants the same environment and quick start", "conceptDOI": "10.5281/zenodo.1436464", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}], "foreignKey": {"id": "5ae85e6f0bd42f30d8877d33", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/NLeSC/Chemical-Analytics-Platform#usage", "repositoryURLs": {"github": ["https://github.com/NLeSC/Chemical-Analytics-Platform"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["YAML"], "readMore": null, "shortStatement": "Chemical Analytics Platform is a freely available Virtual Machine encompassing tools, databases, and KNIME workflows.", "slug": "chemical-analytics-platform", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "common-sense", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T16:22:13Z", "brandName": "CommonSense", "bullets": "- FIXME\n- FIXME\n- FIXME\n", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "b.weel"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.borgdorff"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d38"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "tno", "collection": "organization"}}]}], "getStartedURL": "https://github.com/TNOCS/csWeb", "repositoryURLs": {"github": ["https://github.com/TNOCS/csWeb"]}, "isFeatured": false, "isPublished": false, "license": ["MIT"], "programmingLanguage": ["JavaScript", "TypeScript"], "readMore": null, "shortStatement": "User-friendly web application for showing GIS data on a map.", "slug": "common-sense", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "compressing-the-sky", "collection": "software"}, "createdAt": "2017-11-16T14:36:33Z", "updatedAt": "2018-05-23T16:20:30Z", "brandName": "Compressing-The-Sky project code", "bullets": "- The software is written for the project only\n- The code was used to investigate whether compression of time series improves by using its statistical properties\n", "conceptDOI": "10.5281/zenodo.1050368", "contributors": [{"foreignKey": {"collection": "person", "id": "v.hees"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/compressing-the-sky", "repositoryURLs": {"github": ["https://github.com/NLeSC/compressing-the-sky"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["R"], "readMore": null, "shortStatement": "Exploration of time series compression using statistical properties.", "slug": "compressing-the-sky", "tags": ["Optimized data handling"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "compressing-the-sky-into-a-large-collection-of-statistical-models", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "cwi", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "cptm", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T14:39:26Z", "brandName": "Cross-perspective Topic Modeling", "bullets": "* Experiment with different settings\n* Generate iPython notebooks to visualize results\n* Downloading and preprocessing of the Dutch parliamentary proceedings", "conceptDOI": "10.5281/zenodo.47756", "contributors": [{"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.buitinck"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "p.bos"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/cptm", "repositoryURLs": {"github": ["https://github.com/NLeSC/cptm"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "Cython"], "readMore": "cptm is an implementation of cross-perspective topic modeling, which is is a topic modeling method that simultaneously extract topics and opinions from text. Topics are learned from nouns and opinions from adjectives. To use this tool, you need a corpus that is divided into perspectives. In the DiLiPaD project a perspective refers to a political party. We used this tool to extract topics and opinions from parliamentary proceedings.  ", "shortStatement": "An application that uses cross-perspective topic modeling to extract topics and opinions from text and provides insight into how they change over time.", "slug": "cptm", "tags": ["Text analysis & natural language processing"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "BMCKYRDK"}}, {"foreignKey": {"collection": "mention", "id": "ZV6MC3RR"}}, {"foreignKey": {"collection": "mention", "id": "HX7YJVE7"}}, {"foreignKey": {"collection": "mention", "id": "MFTA57FI"}}, {"foreignKey": {"collection": "mention", "id": "TL4FCCQC"}}, {"foreignKey": {"collection": "mention", "id": "TPIAJWKV"}}, {"foreignKey": {"collection": "mention", "id": "K5GGNX9R"}}], "projects": [{"foreignKey": {"id": "dilipad", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "dedispersion", "collection": "software"}, "createdAt": "2017-11-16T15:03:59Z", "updatedAt": "2018-05-23T16:16:02Z", "brandName": "Dedispersion", "bullets": "* High-performance and portable", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "a.sclocco"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.attema"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/AA-ALERT/Dedispersion", "repositoryURLs": {"github": ["https://github.com/AA-ALERT/Dedispersion"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["C++", "OpenCL"], "readMore": null, "shortStatement": "This library provides easy access to a high-performance, fully tuned radio astronomy dedispersion algorithm.", "slug": "dedispersion", "tags": ["Real time data analysis", "High performance computing", "GPU"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "astrodata", "collection": "software"}}], "mentions": [], "projects": [{"foreignKey": {"id": "aa-alert", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "astron", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "dive", "collection": "software"}, "createdAt": "2017-11-14T13:10:51Z", "updatedAt": "2018-11-27T14:42:36Z", "brandName": "Dive", "bullets": "* Provides interactive web-visualization of data in 3D/2D for data scientists and scientists.\n* One can explore millions of data points interactively\n* Has been used in bioinformatics and forensics projects\n", "conceptDOI": "10.5281/zenodo.598204", "contributors": [{"foreignKey": {"collection": "person", "id": "s.georgievska"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/DiVE", "repositoryURLs": {"github": ["https://github.com/NLeSC/DiVE"]}, "isFeatured": false, "isPublished": true, "license": ["GPL-2.0"], "programmingLanguage": ["JavaScript", "HTML"], "readMore": "When a data scientist has a problem like clustering data, a usual starting point is to \"embed\" and \"see\" the data in 3D or 2D. Ideally she would like to explore data interactively, by being able to search or color the data based on provided metadata. As scientific datasets tend to become larger, current visualization tools are facing scalability issues. Dive is made to provide interactive exploration of (embedded) data in 3D or 2D for million of points. ", "shortStatement": "Interactively explore millions of 2D and 3D data points in your browser, without the need to install anything.", "slug": "dive", "tags": ["Visualization", "Machine learning", "Big data"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "cclustera", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "H5WKLIIZ"}}, {"foreignKey": {"collection": "mention", "id": "NGGCZAJT"}}, {"foreignKey": {"collection": "mention", "id": "87NUJNF4"}}], "projects": [{"foreignKey": {"id": "massive-biological-data-clustering-reporting-and-visualization-tools", "collection": "project"}}, {"foreignKey": {"id": "a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "cbs-knaw", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "docker-couch-admin", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T16:11:05Z", "brandName": "Docker Couch Admin", "bullets": "- FIXME\n- FIXME\n- FIXME", "conceptDOI": "10.5281/zenodo.61301", "contributors": [{"foreignKey": {"collection": "person", "id": "j.borgdorff"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/docker-couch-admin", "repositoryURLs": {"github": ["https://github.com/NLeSC/docker-couch-admin"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript", "HTML"], "readMore": null, "shortStatement": "Configures a web service using angular-schema-form and CouchDB", "slug": "docker-couch-admin", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "eastroviz", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T16:09:44Z", "brandName": "eAstroViz", "bullets": "- FIXME\n- FIXME\n- FIXME", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "r.vannieuwpoort"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/eAstroViz", "repositoryURLs": {"github": ["https://github.com/NLeSC/eAstroViz"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "This tool can convert and visualize radio astronomy measurement sets, as well as most LOFAR intermediate data producs. It also does RFI mitigation.", "slug": "eastroviz", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "eecology-annotation", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-03-06T12:42:49Z", "brandName": "eEcology Annotation Tool", "bullets": "* Ecologists studying bird behavior using the UvA-BiTS system can visualize and annotate the data gathered for a bird in a certain time range\n* The tool retrieves GPS measurements from the UvA-BiTS database and visualizes them so they can be annotated by hand or annotations classified by a machine can be verified\n* It shows all the GPS tracker data in context with the satellite imagery and your own data and annotations\n* It shows acceleration data (seconds timescale) and GPS information (days timescale) in the same interface", "conceptDOI": "10.5281/zenodo.597984", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://www.uva-bits.nl/", "repositoryURLs": {"github": ["https://github.com/NLeSC/eEcology-Annotation-WS"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "JavaScript", "SQL"], "readMore": null, "shortStatement": "Visualize and annotate GPS measurements of bird movements.", "slug": "eecology-annotation", "tags": ["Visualization", "Inter-operability & linked data"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "XR4JDULA"}}, {"foreignKey": {"collection": "mention", "id": "ELRBCSRE"}}, {"foreignKey": {"collection": "mention", "id": "EYMBZYXR"}}, {"foreignKey": {"collection": "mention", "id": "QADFPV4S"}}], "projects": [{"foreignKey": {"id": "eecology", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "eecology-classification", "collection": "software"}, "createdAt": "2017-11-14T13:10:51Z", "updatedAt": "2018-05-23T15:17:34Z", "brandName": "eEecology Classification", "bullets": "- FIXME\n- FIXME\n- FIXME", "conceptDOI": "10.5281/zenodo.594525", "contributors": [{"affiliations": [], "foreignKey": {"id": "c.meijer", "collection": "person"}, "isContactPerson": true}], "getStartedURL": "http://nlesc.github.io/eEcology-Classification/", "repositoryURLs": {"github": ["https://github.com/NLeSC/eEcology-Classification"]}, "isFeatured": false, "isPublished": false, "license": ["GPL-3.0"], "programmingLanguage": ["Java", "JavaScript", "HTML"], "readMore": null, "shortStatement": "FIXME FIXME", "slug": "eecology-classification", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "QADFPV4S"}}, {"foreignKey": {"collection": "mention", "id": "XR4JDULA"}}, {"foreignKey": {"collection": "mention", "id": "EYMBZYXR"}}, {"foreignKey": {"collection": "mention", "id": "ELRBCSRE"}}], "projects": [], "organizations": []}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "eecology-sms-reciever", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-11-26T10:41:47Z", "brandName": "eEcology-SMS-reciever", "bullets": "* Provides a way for eEcologists to read the SMS messags sent by the UvA-BiTS trackers\n* It receives messages from SMSSync Android app and stores them in the UvA-BiTS database\n* When a bird is far away from a base station and an ecologist wants a low frequency way of tracking the bird, this software will capture the SMS message sent by the tracker.\n", "conceptDOI": "10.5281/zenodo.598013", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/eEcology-SMS-reciever", "repositoryURLs": {"github": ["https://github.com/NLeSC/eEcology-SMS-reciever"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "If you have birds flying around carrying UvA-BiTS trackers, then this software can save the SMS messages containing the bird's last known positions which are sent by the tracker to the UvA Bird tracking system's central database.", "slug": "eecology-sms-reciever", "tags": ["Real time data analysis"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "eecology", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "uva", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "eecology-tracker-calendar", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T14:46:01Z", "brandName": "eEcology Tracker calendar", "bullets": "* Ecologists studying bird behavior using the UvA-BiTS system can visualize bird behavior for several years and detect patterns like migration strategies\n* Shows daily statistics like distance traveled, number of measurements, maximum altitude as a heatmap in yearly calendars\n* Allows users to find outliers like measurement errors by choosing their preferred color range and dynamically clip data \n", "conceptDOI": "10.5281/zenodo.1034002", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://www.uva-bits.nl/virtual-lab/", "repositoryURLs": {"github": ["https://github.com/NLeSC/eEcology-script-wrapper"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "SQL", "R", "MATLAB"], "readMore": null, "shortStatement": "Calendar overview with daily statistics of GPS-trackers used to track bird movements. ", "slug": "eecology-tracker-calendar", "tags": ["Visualization"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "7ZWMB2QN"}}], "projects": [{"foreignKey": {"id": "eecology", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "eeg-epilepsy-diagnosis", "collection": "software"}, "createdAt": "2017-11-15T11:58:15Z", "updatedAt": "2018-05-23T15:14:37Z", "brandName": "EEG epilepsy diagnosis", "bullets": "As this was a short lasting project, we mainly focused on processing multi-variate EEG (Electroencephalography) data.\n\nThe software is unique in that it handles the data format and structure used in one particular study, but uses generic external libraries (caret) for the machine learning.", "conceptDOI": "10.5281/zenodo.1043937", "contributors": [{"foreignKey": {"collection": "person", "id": "v.hees"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/EEG-epilepsy-diagnosis", "repositoryURLs": {"github": ["https://github.com/NLeSC/EEG-epilepsy-diagnosis"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["R"], "readMore": null, "shortStatement": "R package developed to extract features from multivariate time series and feed them into a random forest classifier.", "slug": "eeg-epilepsy-diagnosis", "tags": ["Machine learning"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "diagnosis-of-active-epilepsy-in-resource-poor-setting", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "uu", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "embodied-emotions-scripts", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-05-23T16:06:07Z", "brandName": "Embodied Emotions Scripts", "bullets": "* Historical spelling normalization\n* Multi-label text classification\n* Historically accurate emotion model", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/nlesc/embodied-emotions-scripts", "repositoryURLs": {"github": ["https://github.com/nlesc/embodied-emotions-scripts"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Identify changes over time in relations between expressions of emotions and body parts in 17th and 18th century Dutch theater texts.", "slug": "embodied-emotions-scripts", "tags": ["Text analysis & natural language processing", "Machine learning", "Visualization"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "from-sentiment-mining-to-mining-embodied-emotions", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "escatter-pyelsepa", "collection": "software"}, "createdAt": "2017-11-14T12:48:04Z", "updatedAt": "2018-05-28T15:13:30Z", "brandName": "PyELSEPA", "bullets": "- a programmable interface to ELSEPA", "conceptDOI": "10.5281/zenodo.1045193", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "j.hidding", "collection": "person"}, "isContactPerson": true}], "getStartedURL": "https://github.com/eScatter/pyelsepa", "repositoryURLs": {"github": ["https://github.com/eScatter/pyelsepa"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "Fortran"], "readMore": null, "shortStatement": "Python wrapper for ELSEPA, a numeric code for computing elastic scattering cross-sections for electrons and positrons off neutral atoms.", "slug": "pyelsepa", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "fast-open-source-simulator-of-low-energy-scattering-of-charged-particles-in", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "tudelft", "collection": "organization"}}, {"foreignKey": {"id": "nikhef", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Tommos0"}, {"primaryKey": {"id": "ewaterleaf", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-09-27T08:12:14Z", "brandName": "eWaterLeaf", "bullets": "* Simple visualisation of Geospatial data.\n* Web based Visualisation of NetCDF data.\n* Little to no configuration necessary.", "conceptDOI": "10.5281/zenodo.594690", "contributors": [{"foreignKey": {"collection": "person", "id": "n.drost"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/eWaterCycle/eWaterleaf", "repositoryURLs": {"github": ["https://github.com/eWaterCycle/eWaterleaf"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript"], "readMore": "eWaterLeaf is a very simple Web based Visualization for Gespatial data. It supports any NetCDF-CF compliant file, the most supported format in Geosciences.\n\neWaterLeaf is based on the widespread Web Map Service (WPS) standard. Next to a Javascript visualization based on Leaflet (hence the name), it also includes a server (based on ncWMS) for serving any NetCDF-CF file.", "shortStatement": "If you have large amounts of Geospatial grid-based data you would like to explore quickly, eWaterLeaf could be the visualisation for you.", "slug": "ewaterleaf", "tags": ["Visualization"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "ewatercycle", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "tudelft", "collection": "organization"}}, {"foreignKey": {"id": "uu", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "extjs-datetime", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T16:18:28Z", "brandName": "DateTime input field for Ext JS", "bullets": "* A Javascript application software developer who is working with the ExtJSv3 javascript User Interface framework  and needs a widget which combines the date input and time input.\n* It uses UTC timezone instead of the for Javascript default local timezone, which is useful when your data is also in UTC.", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/ExtJS-DateTime", "repositoryURLs": {"github": ["https://github.com/NLeSC/ExtJS-DateTime"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript"], "readMore": null, "shortStatement": "JavaScript ExtJS form element for datetime input fields.", "slug": "extjs-datetime", "tags": ["Visualization"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "eecology", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "fairdatapoint", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-26T10:53:09Z", "brandName": "FAIR Data Point", "bullets": "* Makes your data assets structured and available through Web API\n* Provides  standardized descriptions (RDF-based metadata) using controlled vocabularies and ontologies\n* Enables client applications to retrieve, aggregate or filter (meta)data from distributed FDPs \n", "conceptDOI": "10.5281/zenodo.1083950", "contributors": [{"foreignKey": {"collection": "person", "id": "a.kuzniar"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d3a"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "lumc", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d3b"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d3c"}, "isContactPerson": false, "affiliations": []}], "getStartedURL": "https://github.com/NLeSC/ODEX-FAIRDataPoint", "repositoryURLs": {"github": ["https://github.com/NLeSC/ODEX-FAIRDataPoint"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "Java"], "readMore": null, "shortStatement": "RESTful web service that enables data owners to expose their data sets using rich machine-readable metadata.", "slug": "fairdatapoint", "tags": ["Inter-operability & linked data"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "4CUCX6ND"}}, {"foreignKey": {"collection": "mention", "id": "YQ4334H7"}}, {"foreignKey": {"collection": "mention", "id": "KF23ZSVX"}}], "projects": [{"foreignKey": {"id": "odex4all", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "lumc", "collection": "organization"}}, {"foreignKey": {"id": "dtl", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "fastmlc", "collection": "software"}, "createdAt": "2017-11-14T13:30:36Z", "updatedAt": "2018-10-15T09:56:12Z", "brandName": "FastMLC", "bullets": "* Provides an efficient and high precision clustering and embedding of large datasets followed by interactive 3D visualization\n* The only tool of this kind ", "conceptDOI": "10.5281/zenodo.926819", "contributors": [{"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d3d"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "75b09ab5-42d0-4646-81b9-4398c7f2f6f1", "collection": "organization"}}]}, {"foreignKey": {"id": "5ae85e6f0bd42f30d8877d3e", "collection": "person"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "75b09ab5-42d0-4646-81b9-4398c7f2f6f1", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "s.georgievska"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d3f"}, "isContactPerson": false, "affiliations": []}, {"foreignKey": {"collection": "person", "id": "a.kuzniar"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/FastMLC/fMLC", "repositoryURLs": {"github": ["https://github.com/FastMLC/fMLC"]}, "isFeatured": false, "isPublished": true, "license": ["GPL-3.0"], "programmingLanguage": ["C++", "JavaScript"], "readMore": null, "shortStatement": "Detect clusters in for example large collections of DNA or protein sequences, and visualize the results in a web browser.", "slug": "fastmlc", "tags": ["Visualization", "Machine learning", "Big data"], "testimonials": [{"person": "Anonymous reviewer", "text": "A very nice tool to cluster and visualize sequences. The work is well presented, the web application easy to use and the manuscript well written."}], "related": {"software": [{"foreignKey": {"id": "dive", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "87NUJNF4"}}, {"foreignKey": {"id": "BQ335DNH", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "massive-biological-data-clustering-reporting-and-visualization-tools", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "75b09ab5-42d0-4646-81b9-4398c7f2f6f1", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "finding-journalists", "collection": "software"}, "createdAt": "2017-11-14T12:28:17Z", "updatedAt": "2018-11-26T10:58:28Z", "brandName": "Lysander", "bullets": "* the software helps in finding unknown Twitter users related to a known group of users.\n* target audience for this software: researchers\n* discovering previously unknown Twitter users related to a known group of users\n* suggesting Twitter users related to a known group of users\n* useful results for finding political journalists based on group of politicians", "conceptDOI": "10.5281/zenodo.1045122", "contributors": [{"foreignKey": {"collection": "person", "id": "e.tjongkimsang"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/online-behaviour/find-journalists", "repositoryURLs": {"github": ["https://github.com/online-behaviour/find-journalists"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "For analysis of online behaviour of groups, the first task is to find out who the members of the group are. Usually we know a few key people but not the whole group. We can find other people of the group by checking which people are related to the key people. On Twitter we can use the asymmetrical follower relation to expand groups: if a person follows many members of a group and many members of the group follow this person, the person is likely to be a member of the group. This software package uses this idea for suggesting extra members for groups on Twitter.", "shortStatement": "Find people on Twitter given a small initial set of interesting people.", "slug": "finding-journalists", "tags": ["Text analysis & natural language processing"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "online-behaviour-machine-learning", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "NULJGSL5"}}], "projects": [{"foreignKey": {"id": "automated-analysis-of-online-behaviour-on-social-media", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "university.of.groningen", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "frbcat-web", "collection": "software"}, "createdAt": "2017-11-16T15:03:59Z", "updatedAt": "2018-11-26T11:03:34Z", "brandName": "frbcat-web", "bullets": "* Provides a web frontend to the Fast Radio Burst (FRB) Catalogue.\n* Enables to quickly browse and filter the catalogue of FRBs.\n* No need to write your own interface to the database.\n* The [Fast Radio Bursts (FRBs) catalog](http://www.frbcat.org) is used by many scientists.", "conceptDOI": "10.5281/zenodo.1051033", "contributors": [{"foreignKey": {"collection": "person", "id": "r.vanharen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/aa-alert/frbcat-web", "repositoryURLs": {"github": ["https://github.com/AA-ALERT/frbcat-web"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript", "SQL"], "readMore": "frbcat-web provides the web frontend to the FRB Catalogue.", "shortStatement": "Provides an easy to-use web frontend to browse and filter the Fast Radio Burst Catalogue.", "slug": "frbcat-web", "tags": ["Visualization", "Optimized data handling"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "frbcatdb", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "GGYEN2YS"}}, {"foreignKey": {"collection": "mention", "id": "U5XQVYGV"}}], "projects": [{"foreignKey": {"id": "aa-alert", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "astron", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "frbcatdb", "collection": "software"}, "createdAt": "2017-11-16T14:46:53Z", "updatedAt": "2018-11-27T14:48:56Z", "brandName": "frbcatdb", "bullets": "* Provides a relational database interface to Virtual Observation Event (VOEvent) data.\n* Stores VOEvents into a relational database.\n* Makes VOEvent data more easily accessible for analysis.\n* Succesfully used as a backend for the [Fast Radio Bursts (FRBs) catalog](http://www.frbcat.org).", "conceptDOI": "10.5281/zenodo.1051039", "contributors": [{"foreignKey": {"collection": "person", "id": "r.vanharen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "5b4a519a-4523-4ca9-b6d8-2b08d8b057e4", "collection": "organization"}}]}], "getStartedURL": "http://frbcatdb.readthedocs.io/en/latest/?badge=latest", "repositoryURLs": {"github": ["https://github.com/AA-ALERT/frbcatdb"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "The frbcatdb is a database to store a catalog of Fast Radio Bursts (FRBs). The DB is intended to contain old FRB events as well as new FRBs detected by the AA-ALERT FRB detection pipeline from Apertif observations and also possible follow-up observations or others FRBs detected by other telescopes. The frbcatdb is attached to the VOEvent backbone and uses this infrastructure as its source.", "shortStatement": "A database to store a catalog of Fast Radio Bursts and expose them as Virtual Observation Events.", "slug": "frbcatdb", "tags": ["Optimized data handling"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "frbcat-web", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "U5XQVYGV"}}, {"foreignKey": {"collection": "mention", "id": "GGYEN2YS"}}], "projects": [{"foreignKey": {"id": "aa-alert", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "astron", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "google-earth-toolbox-for-matlab", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-09-25T14:46:29Z", "brandName": "GoogleEarth Toolbox for MATLAB", "bullets": "* Export spatio-temporal data from MATLAB to GoogleEarth's KML format\n* Comes with extensive HTML documentation\n\n", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d40"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "uva", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "j.spaaks"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/scottleedavis/googleearthtoolbox", "repositoryURLs": {"github": ["https://github.com/scottleedavis/googleearthtoolbox"]}, "isFeatured": false, "isPublished": false, "license": ["BSD-2-Clause"], "programmingLanguage": ["MATLAB"], "readMore": null, "shortStatement": "Export data from MATLAB to GoogleEarth's KML format.", "slug": "google-earth-toolbox-for-matlab", "tags": ["Visualization"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "grlc", "collection": "software"}, "createdAt": "2017-11-16T14:24:47Z", "updatedAt": "2019-03-20T09:46:16Z", "brandName": "grlc", "bullets": " * Builds a web API for users who need access to triple store data without requiring SPARQL\n * Creates an API from SPARQL queries stored on a github repository\n * No need to know how to write SPARQL queries\n ", "conceptDOI": "10.5281/zenodo.1064391", "contributors": [{"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d41"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d42"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "dans", "collection": "organization"}}]}], "getStartedURL": "http://grlc.io/", "repositoryURLs": {"github": ["https://github.com/CLARIAH/grlc"]}, "isFeatured": false, "isPublished": true, "license": ["MIT"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Builds a web API from SPARQL queries hosted on GitHub to accessing triple store data.", "slug": "grlc", "tags": ["Inter-operability & linked data"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "S54NZNZD"}}, {"foreignKey": {"collection": "mention", "id": "AF2B7JUP"}}, {"foreignKey": {"id": "K7PHLNSV", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "dive", "collection": "project"}}, {"foreignKey": {"id": "prediction-of-candidate-genes-for-traits-using-interoperable-genome-annotat", "collection": "project"}}, {"foreignKey": {"id": "data-quality-in-a-distributed-learning-environment", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "3a45ea34-6f1e-4a57-8666-17278f42e48c", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "c-martinez"}, {"primaryKey": {"id": "hadrianus-scripts", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-11-27T14:53:36Z", "brandName": "Hadrianus scripts", "bullets": "* Gives examples of how to define a common ontology for very different databases\n* Combine cultural heritage heterogeneous database infrastructures using linked data tools and ontologies\n* Every cultural heritage scholar has a unique perspective on their subject; this is reflected in their databases\n* The Humanities treasure and stimulate such richness of perspectives; this is a challenge for Digital Humanities and a great opportunity for eScience", "conceptDOI": "10.5281/zenodo.1462264", "contributors": [{"foreignKey": {"collection": "person", "id": "p.bos"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "a.kuzniar"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/hadrianus-scripts", "repositoryURLs": {"github": ["https://github.com/NLeSC/hadrianus-scripts"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "Perl", "SQL", "SPARQL"], "readMore": "In the Hadrianus project, we aimed to enrich the existing [Hadrianus website](http://www.hadrianus.it)  with data from various other sources. The Hadrianus website revolves around the connection between Dutch artists and the city of Rome. While the current manually curated database offers a very rich picture of this connection already, many more discoveries could be made by adding data on the same or related artists and works of art from other sources. The challenge of this project was to figure out how to do this in an automated way that would enable some uniform way of linking and comparing data, but still retain all the richness of detail that each database brings to the table. In this set of scripts, we have explored one way to do so, namely by using the linked data Virtuoso platform, that can transform relational databases to linked databases. The biggest challenge in this was to define a common ontology.", "shortStatement": "Scripts that transform cultural heritage relational databases into linked data by using cultural heritage ontologies.", "slug": "hadrianus-scripts", "tags": ["Inter-operability & linked data"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "handrianvs-a-digital-gateway-to-the-dutch-presence-in-rome-through-the-ages", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "knir", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "hypercanny", "collection": "software"}, "createdAt": "2017-11-16T14:36:33Z", "updatedAt": "2018-11-27T14:55:12Z", "brandName": "HyperCanny", "bullets": "- Computes edges in large data sets\n- Works in any number of dimensions\n- Easily accessible from Python using a Cython wrapper. The Python interface is geared towards applications in climate science.\n- C++ and Python interfaces\n- The only (findable) implementation of Canny's algorithm in more than two dimensions", "conceptDOI": "10.5281/zenodo.1051130", "contributors": [{"foreignKey": {"collection": "person", "id": "j.hidding"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/abrupt-climate/hyper-canny", "repositoryURLs": {"github": ["https://github.com/abrupt-climate/hyper-canny"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["C++", "Python"], "readMore": null, "shortStatement": "Finds edges in high-dimensional data using the Canny algorithm.", "slug": "hypercanny", "tags": ["High performance computing"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "data-mining-tools-for-abrupt-climate-change", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "wur", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "kernel_tuner", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2019-04-30T12:34:24Z", "brandName": "Kernel Tuner", "bullets": "* Allows developers to easily unit test and auto-tune GPU code\n* Generic auto-tuning of user-defined parameters for CUDA, OpenCL, and C kernels\n* Supports more than 20 different search optimization methods to speedup tuning\n* Successfully used in 5 different eScience projects, across various disciplines", "conceptDOI": "10.5281/zenodo.1220113", "contributors": [{"foreignKey": {"collection": "person", "id": "b.vanwerkhoven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "a.sclocco"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "p.bos"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "i.pelupessy"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "f.zapata"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.hidding"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "h.spreeuw"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "n.renaud"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "cwi", "collection": "organization"}}], "foreignKey": {"id": "513f1adb-b022-4d26-b40d-27c71d0525df", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/benvanwerkhoven/kernel_tuner", "repositoryURLs": {"github": ["https://github.com/benvanwerkhoven/kernel_tuner"]}, "isFeatured": true, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "CUDA", "OpenCL"], "readMore": "Kernel Tuner simplifies the development of efficient GPU programs, or _kernels_. It does so by making kernels written in C/C++, OpenCL, or CUDA accessible from Python, while taking care of the required synchronization between data kept in\nhost memory and data kept in device memory.\n\nThis has a number of advantages. First, it simplifies _auto-tuning_ of the kernel parameters. In fact, Kernel Tuner comes standard with a variety of strategies for efficiently searching the parameter space, leading to  greatly improved performance of tuned kernels. Second, it allows for unit testing of GPU code from within Python. \n\nKernel Tuner does not add any additional dependencies to the kernel code, and does not require extensive code changes. Furthermore, it is noteworthy that kernels tuned by Kernel Tuner do not require any changes after tuning to make them production ready--tuned kernels can be used as-is from any host programming language.\n", "shortStatement": "Kernel Tuner greatly simplifies the development of highly-optimized and auto-tuned CUDA, OpenCL, and C code, supporting many advanced use-cases and optimization strategies that speed up the auto-tuning process.", "slug": "kernel-tuner", "tags": ["GPU", "High performance computing", "Multi-scale & multi model simulations", "Real time data analysis", "Optimized data handling", "Big data"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "UXH8GTHF"}}, {"foreignKey": {"collection": "mention", "id": "BV97KLFC"}}, {"foreignKey": {"collection": "mention", "id": "GB8BVE6F"}}, {"foreignKey": {"collection": "mention", "id": "5LB7VFQA"}}, {"foreignKey": {"collection": "mention", "id": "3Q3DWW4N"}}, {"foreignKey": {"collection": "mention", "id": "E94KZJZP"}}, {"foreignKey": {"collection": "mention", "id": "7N3E58NF"}}, {"foreignKey": {"collection": "mention", "id": "E7FA5UNF"}}, {"foreignKey": {"collection": "mention", "id": "ZBI3XQU7"}}, {"foreignKey": {"collection": "mention", "id": "WMCV6WE7"}}, {"foreignKey": {"collection": "mention", "id": "ZEMZ3HN8"}}, {"foreignKey": {"id": "8RB3P9GS", "collection": "mention"}}, {"foreignKey": {"id": "D88CBZH7", "collection": "mention"}}, {"foreignKey": {"id": "RQ6ZWG92", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "collection": "project"}}, {"foreignKey": {"id": "3d-geospatial-data-exploration-for-modern-risk-management-systems", "collection": "project"}}, {"foreignKey": {"id": "parallelisation-of-multi-point-cloud-registration", "collection": "project"}}, {"foreignKey": {"id": "real-time-detection-of-neutrinos-from-the-distant-universe", "collection": "project"}}, {"foreignKey": {"id": "dirac", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "benvanwerkhoven"}, {"primaryKey": {"id": "knime-archetype", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T15:49:50Z", "brandName": "KNIME node archetype", "bullets": "* For KNIME node developers who like to have  quick start and automated builds\n* Generates a project skeleton that contains all you need to develop your own KNIME nodes\n* Automates tests and deploying the node to an update site\n* Includes dependency management and test coverage\n* Used to create all KNIME nodes in the 3D-e-Chem project", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/tycho-knime-node-archetype", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/tycho-knime-node-archetype"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "Want to write your own KNIME node Then use the KNIME node archetype to generate a node skeleton repository with sample code.", "slug": "knime-archetype", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "LRNNKXZF"}}], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "knime-gpcrdb", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T15:19:04Z", "brandName": "KNIME GPCRdb nodes", "bullets": "* For cheminformaticians who are working with GPCR proteins in KNIME workflows.\n* KNIME nodes to interact with GPCRdb webservice\n* You don't have to download csv files from the GPCRdb website and load them into a KNIME workflow, but can use nodes which fetch for example a protein sequence alignment for you", "conceptDOI": "10.5281/zenodo.597174", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d43"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "vua", "collection": "organization"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/knime-gpcrdb#installation", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-gpcrdb"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "A node for the KNIME workflow systems that allows you to retrieve data about your favorite G protein-coupled receptors from gpcrdb.org.", "slug": "knime-gpcrdb", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "QGIC4HKR"}}], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "knime-klifs", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-06-13T11:57:39Z", "brandName": "KLIFS KNIME nodes", "bullets": "* For cheminformations who are working with kinase proteins in KNIME workflows.\n* KNIME nodes to interact with KLIFS website", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "vua", "collection": "organization"}}], "foreignKey": {"id": "5ae85e6f0bd42f30d8877d43", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/3D-e-Chem/knime-klifs", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-klifs"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "If you are working in the KNIME worflow platform and need data about your favorite kinase receptor ligand interaction, then these nodes are for you.", "slug": "knime-klifs", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "5LDL5W9Z"}}, {"foreignKey": {"collection": "mention", "id": "SJYGYP3V"}}, {"foreignKey": {"collection": "mention", "id": "TJQZAWWY"}}], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "knime-molviewer", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T10:53:05Z", "brandName": "KNIME molecule viewer nodes", "bullets": "* Provides cheminformatics trying to model proteins within KNIME a way to view them\n* Adds  nodes to KNIME to visualize proteins, small molecules and pharmacophores\n* Adds support to KNIME to  handle viewing big molecules\n* Used to compare pharmacophore generation tools\n* Used to check ligand repurposing", "conceptDOI": "10.5281/zenodo.597231", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "vua", "collection": "organization"}}], "foreignKey": {"id": "5ae85e6f0bd42f30d8877d43", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/3D-e-Chem/knime-molviewer", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-molviewer"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "A 3D viewer for large molecules for the KNIME workflow system.", "slug": "knime-molviewer", "tags": ["Visualization", "Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "knime-sstea", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-11-27T15:14:24Z", "brandName": "KNIME ss-TEA node", "bullets": "* For bioinformaticians or cheminformaticians  who have no 3D structure of their protein, just a protein sequence and want to know which position is likely to bind a ligand.\n* It takes a big multi species multiple sequence alignment and a list of subfamily members to produce a score for each position in the sequence alignment.\n* Can tell which residue in a protein is likely to bind a ligand without 3D information\n* Ranked among best model in the GPCR dock 2010 competition.  ss-TEA is as part of [Snooker pharmacophore generation tool](https://pubs.acs.org/doi/abs/10.1021/ci200088d)", "conceptDOI": "10.5281/zenodo.597241", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/knime-sstea", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-sstea"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "A node for the KNIME workflow systems that allows you to identify which residue position in a big protein sequence alignment is specific to ligand binding.", "slug": "knime-sstea", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "knime-testflow", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-11-27T15:14:16Z", "brandName": "KNIME Testflow", "bullets": "* KNIME node developers can run test workflows, inside KNIME or from the command line already, this software allows you to test a workflow from JUnit test\n* Allows you to write JUnit tests not only for unit tests, but also for integration test by running workflows inside a JUnit test\n* By running the test workflow inside a JUnit test, you get the JUnit benefits like automation and coverage\n* Used in all KNIME nodes made in the 3D-e-Chem project to test that the nodes are working as expected\n", "conceptDOI": "10.5281/zenodo.55805", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/3D-e-Chem/knime-testflow", "repositoryURLs": {"github": ["https://github.com/3D-e-Chem/knime-testflow"]}, "isFeatured": false, "isPublished": true, "license": ["GPL-3.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "Allows you to test KNIME nodes automatically using JUnit.", "slug": "knime-testflow", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "LRNNKXZF"}}], "projects": [{"foreignKey": {"id": "3d-e-chem", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "linked-data-platform-for-animal-breeding-genomics", "collection": "software"}, "createdAt": "2017-11-14T13:17:46Z", "updatedAt": "2018-05-31T19:11:38Z", "brandName": "abg-ld", "bullets": "* provides an integrated resource on pig for animal researchers and breeders\n* enables queries for genomic regions or genes associated with traits of interest\n* biological concepts and  their relationships are described by (domain-specific) controlled vocabularies or ontologies", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "a.kuzniar"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d46"}, "isContactPerson": false, "affiliations": []}], "getStartedURL": "https://github.com/candYgene/abg-ld", "repositoryURLs": {"github": ["https://github.com/candYgene/abg-ld"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["SPARQL", "SQL", "Python"], "readMore": null, "shortStatement": "Easy access to integrated animal-specific data on genes associated with traits of interest.", "slug": "linked-data-platform-for-animal-breeding-genomics", "tags": ["Inter-operability & linked data"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "T76UXCBC"}}], "projects": [{"foreignKey": {"id": "prediction-of-candidate-genes-for-traits-using-interoperable-genome-annotat", "collection": "project"}}, {"foreignKey": {"id": "odex4all", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "wur", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "arnikz"}, {"primaryKey": {"id": "linked-data-platform-for-plant-breeding-genomics", "collection": "software"}, "createdAt": "2017-11-14T13:17:46Z", "updatedAt": "2019-02-14T11:57:46Z", "brandName": "pbg-ld", "bullets": "* provides an integrated resource on potato and (wild) tomato species for plant researchers and breeders\n* enables queries for genomic regions or genes associated with traits of interest\n* biological concepts and  their relationships are described by (domain-specific) ontologies and controlled vocabularies", "conceptDOI": "10.5281/zenodo.1458168", "contributors": [{"foreignKey": {"collection": "person", "id": "a.kuzniar"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d47"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "wur", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/candYgene/pbg-ld", "repositoryURLs": {"github": ["https://github.com/candYgene/pbg-ld"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["SPARQL", "SQL", "Python", "Shell scripts"], "readMore": null, "shortStatement": "Provides easy access to integrated plant-specific data on genes associated with traits of interest.", "slug": "linked-data-platform-for-plant-breeding-genomics", "tags": ["Inter-operability & linked data"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "siga-py", "collection": "software"}}, {"foreignKey": {"id": "qtl-tableminer", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "MXM5JHM7"}}, {"foreignKey": {"collection": "mention", "id": "M2M5QEKW"}}, {"foreignKey": {"id": "K7PHLNSV", "collection": "mention"}}, {"foreignKey": {"id": "T76UXCBC", "collection": "mention"}}, {"foreignKey": {"id": "FTGDUDRG", "collection": "mention"}}, {"foreignKey": {"id": "MKKKNJTS", "collection": "mention"}}, {"foreignKey": {"id": "UVQEMWU7", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "prediction-of-candidate-genes-for-traits-using-interoperable-genome-annotat", "collection": "project"}}, {"foreignKey": {"id": "odex4all", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "wur", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "arnikz"}, {"primaryKey": {"id": "magma", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-26T12:21:56Z", "brandName": "MAGMa", "bullets": "- Supports mass spectrometrists to chemically annotate fragmentation data\n- Retrieves and ranks candidate molecules and substructures for parent and product ions\n- Provides metabolic reaction rules to generate candidate molecules\n- Provides a powerful user interface to interpret the results", "conceptDOI": "10.5281/zenodo.1043225", "contributors": [{"foreignKey": {"collection": "person", "id": "l.ridder"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "m.sanders"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://www.emetabolomics.org", "repositoryURLs": {"github": ["https://github.com/NLeSC/MAGMa"]}, "isFeatured": true, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "JavaScript", "Cython"], "readMore": null, "shortStatement": "MAGMa is an online application for the automatic chemical annotation of mass spectrometry data.", "slug": "magma", "tags": ["Visualization", "Big data"], "testimonials": [{"affiliation": "Department of Civil & Environmental Engineering, Duke University", "person": "Lee Ferguson", "text": "My group has had an excellent run of almost 1 year now running MAGMa as part of our cluster-based compound ID workflow - it is really a great program."}], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "9EZ45E7K"}}, {"foreignKey": {"collection": "mention", "id": "ILSAVKKB"}}, {"foreignKey": {"collection": "mention", "id": "ALDIGA49"}}, {"foreignKey": {"collection": "mention", "id": "VFQTKBVE"}}, {"foreignKey": {"collection": "mention", "id": "LWHCGGKW"}}, {"foreignKey": {"collection": "mention", "id": "F86WT39N"}}, {"foreignKey": {"collection": "mention", "id": "YYXJGIYZ"}}, {"foreignKey": {"collection": "mention", "id": "HVSB4FE9"}}, {"foreignKey": {"collection": "mention", "id": "CTA5UTXW"}}, {"foreignKey": {"collection": "mention", "id": "HQBEC5X5"}}, {"foreignKey": {"collection": "mention", "id": "FMBZAZKV"}}, {"foreignKey": {"collection": "mention", "id": "V9VMB8ZH"}}], "projects": [{"foreignKey": {"id": "chemical-informatics-for-metabolite-identification-and-biochemical-network", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "wur", "collection": "organization"}}, {"foreignKey": {"id": "ea019401-6169-45dc-98b5-d14f35a3638d", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "magnesium", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T15:35:46Z", "brandName": "Magnesium", "bullets": "- FIXME\n- FIXME\n- FIXME", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "j.maassen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/eSalsa-MPI", "repositoryURLs": {"github": ["https://github.com/NLeSC/eSalsa-MPI"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["C", "Java"], "readMore": null, "shortStatement": "An MPI wrapper library that allows traditional MPI applications to be run on a combination of multiple supercomputers or clusters, without changing a single line of code in the application.", "slug": "magnesium", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "massivepotreeconverter", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T15:34:53Z", "brandName": "Massive PotreeConverter", "bullets": "* For people wanting to visualize country sized point cloud data-sets using the Potree viewer, a way to convert the huge data-set for viewing in reasonable time.\n* This converter provides a way to convert the point cloud data to potree readable format in parallel instead of sequentially\n* The converter offered by potree will take a very long time to convert a huge data set as it will process each point in sequence, this software breaks the data-set up into pieces which can be converted in parallel, shortening the conversion time significantly\n* The converter was used for the visualization (http://ahn2.pointclouds.nl/) of the 640 billion point data-set of the Netherlands\n", "conceptDOI": "10.5281/zenodo.910906", "contributors": [{"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "m.vanmeersbergen"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/Massive-PotreeConverter/blob/master/README.md", "repositoryURLs": {"github": ["https://github.com/NLeSC/Massive-PotreeConverter"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Use parallel processing to quickly convert large point cloud data sets to the format used by the Potree viewer.", "slug": "massivepotreeconverter", "tags": ["Optimized data handling", "Big data"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "ahn2webviewer", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "6WURICLY"}}], "projects": [{"foreignKey": {"id": "mapping-the-via-appia-in-3d", "collection": "project"}}, {"foreignKey": {"id": "massive-point-clouds-for-esciences", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "fugro", "collection": "organization"}}, {"foreignKey": {"id": "potree", "collection": "organization"}}, {"foreignKey": {"id": "tudelft", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "mcfly", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-28T09:50:48Z", "brandName": "mcfly", "bullets": "* Provides starting point for researchers to use deep learning \n* Creates deep learning models to classify time series data\n* Derives features automatically from raw data\n* Helps with finding a suitable model architecture and hyperparameters\n* Has a tutorial in Python to get you started!\n", "conceptDOI": "10.5281/zenodo.596127", "contributors": [{"foreignKey": {"collection": "person", "id": "c.meijer"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "d.vankuppevelt"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "v.hees"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "p.bos"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "m.kuzak"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "a.vanderploeg"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/mcfly/wiki/Home---mcfly", "repositoryURLs": {"github": ["https://github.com/NLeSC/mcfly"]}, "isFeatured": true, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "Deep learning is a powerful tool to help with the automated classification of data. However, designing a deep learning network that works well for your data is not trivial: it requires the user to choose the number of layers in the network, the number of nodes in each layer, the type of each layer, and so forth. With so many degrees of freedom, finding the network that is right for your data is an arduous task. Moreover, each network still needs to be calibrated or _trained_ before it can be usefully applied for automated classification of data. \n\nmcfly simplifies this process by making explicit the required steps while offering useful default values at each step. mcfly then proceeds by trying out many different network configurations, training each one to the data provided by the user. It subsequently lists the performance of each network, along with a visualization that helps the user judge each network's tendency to overfit or underfit the data. \n", "shortStatement": "Helps you find a suitable neural network configuration for deep learning on time series.", "slug": "mcfly", "tags": ["Machine learning"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "6HCZNBN9"}}, {"foreignKey": {"collection": "mention", "id": "N8QDKSBT"}}, {"foreignKey": {"collection": "mention", "id": "SKVHLBFM"}}, {"foreignKey": {"collection": "mention", "id": "VVUWP3ZW"}}, {"foreignKey": {"collection": "mention", "id": "2QD8M69G"}}, {"foreignKey": {"collection": "mention", "id": "S26RLGSC"}}, {"foreignKey": {"id": "LGN73A98", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "googling-the-cancer-genome", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "vincentvanhees"}, {"primaryKey": {"id": "mdstudio", "collection": "software"}, "createdAt": "2017-11-14T13:13:32Z", "updatedAt": "2018-11-26T12:32:16Z", "brandName": "MDStudio", "bullets": "* Molecular dynamics workflow creation and execution for biochemists\n* Micro-service based workflow management system\n* Flexible, interactive workflow execution locally or on HPC\n* Support for ATB, Gromacs, PLANTS, Paradocks, and many other tools", "conceptDOI": "10.5281/zenodo.1435683", "contributors": [{"foreignKey": {"collection": "person", "id": "f.zapata"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d48"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"id": "vua", "collection": "organization"}}]}, {"affiliations": [{"foreignKey": {"id": "d54acaaf-f296-4933-a321-1d4369bc4cf4", "collection": "organization"}}], "foreignKey": {"id": "9f1a937f-6a07-41a6-9817-28b9b22e144e", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "d54acaaf-f296-4933-a321-1d4369bc4cf4", "collection": "organization"}}], "foreignKey": {"id": "aaf3b29b-a6f8-43c8-817a-a3f4ff849775", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/MD-Studio/MDStudio", "repositoryURLs": {"github": ["https://github.com/MD-Studio/MDStudio"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "MDStudio provides biochemistry researchers in science and industry with the easiest and most flexible solution to running  molecular dynamics-based workflows. It is community-developed open source software.\n", "shortStatement": "A tool to run molecular dynamics workflows.", "slug": "mdstudio", "tags": ["Real time data analysis", "High performance computing", "Workflow technologies"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "cerise", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "JB58V7MQ"}}, {"foreignKey": {"collection": "mention", "id": "93M8P57G"}}, {"foreignKey": {"collection": "mention", "id": "U49LQS8C"}}, {"foreignKey": {"collection": "mention", "id": "UNHDCL9R"}}, {"foreignKey": {"collection": "mention", "id": "F6ZBSZLR"}}, {"foreignKey": {"collection": "mention", "id": "JFRV66FB"}}, {"foreignKey": {"collection": "mention", "id": "MUJ2XX3D"}}, {"foreignKey": {"collection": "mention", "id": "ACTFSCWS"}}, {"foreignKey": {"collection": "mention", "id": "JT5NQPMH"}}, {"foreignKey": {"collection": "mention", "id": "HPAM2EY8"}}], "projects": [{"foreignKey": {"id": "enhancing-protein-drug-binding-prediction", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "d54acaaf-f296-4933-a321-1d4369bc4cf4", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "mmsoda-toolbox-for-matlab", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-26T12:26:08Z", "brandName": "MMSODA Toolbox for MATLAB", "bullets": "* Provides one programming interface to single-objective and multi-objective versions of SCEM-UA (by Vrugt et al.)\n* Provides a variety of plotting functions to monitor the optimization's progress and to improve understanding of the optimization results\n* Can do simplified data assimilation (direct insertion)\n* Can run locally or distributed on a cluster\n* Comes with a tutorial manual as well as extensive HTML documentation", "conceptDOI": "10.5281/zenodo.1064714", "contributors": [{"foreignKey": {"collection": "person", "id": "j.spaaks"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d49"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "uva", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e6f0bd42f30d8877d4a"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "uva", "collection": "organization"}}]}], "getStartedURL": "https://github.com/NLeSC/esibayes", "repositoryURLs": {"github": ["https://github.com/NLeSC/esibayes"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["MATLAB", "C"], "readMore": null, "shortStatement": "MATLAB toolbox for global optimization and state estimation of dynamic models using distributed computing.", "slug": "mmsoda-toolbox-for-matlab", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "esibayes", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "surfsara", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "netcdf2littler", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2019-03-20T12:48:38Z", "brandName": "NetCDF2LittleR", "bullets": "- FIXME\n- FIXME\n- FIXME\n", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "r.vanharen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/rvanharen/netcdf2littler", "repositoryURLs": {"github": ["https://github.com/rvanharen/netcdf2littler"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Fortran"], "readMore": null, "shortStatement": "Fortran application to convert NetCDF files to the Little-R format.", "slug": "netcdf2littler", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "era-urban", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "wur", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "rvanharen"}, {"primaryKey": {"id": "nlppln", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2019-01-29T09:04:14Z", "brandName": "nlppln", "bullets": "* Quickly build text mining and/or nlp workflows in Python\n* Combine tools written in different programming languages", "conceptDOI": "10.5281/zenodo.1116323", "contributors": [{"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "d.vankuppevelt", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "http://nlppln.readthedocs.io/en/latest/installation.html", "repositoryURLs": {"github": ["https://github.com/nlppln/nlppln"]}, "isFeatured": true, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "Digital Humanities research often involves Natural Language Processing (NLP), in which a body of natural language text, or _corpus_, is analyzed using software. While there are many software packages available, constructing new research\nanalyses by combining (parts of) existing packages remains challenging. This is due to the fact that individual software packages are designed to do a task and to do that task well; they are not primarily designed to interact with other,\ncomplementary packages. Another problem is that there are many tools available for English, but not for other languages.\n\nnlppln (pronounced 'NLP pipeline') is an open source Python package that helps to address these problems, by making it easy to package existing tools in a uniform way as defined in the CWL (Common Workflow Language) standard for describing data analysis workflows. nlppln includes components to do tasks that are common in NLP, such as tokenization (multiple languages), lemmatization (for Dutch), and named entity recognition (for Dutch). These components are based on existing tools. Users can easily construct new analysis workflows by combining these pre-baked components with tools of their own creation.\n\nBesides improving interoperability, nlppln also keeps a formal record of all steps taken in a workflow. This makes the research more transparent, and improves reproducibility.\n", "shortStatement": "A flexible solution to build text mining workflows that allows you to quickly combine Natural Language Processing tools from different sources.", "slug": "nlppln", "tags": ["Text analysis & natural language processing"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "scriptcwl", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "4SXMEX3U"}}, {"foreignKey": {"collection": "mention", "id": "EZTF2XWE"}}, {"foreignKey": {"collection": "mention", "id": "I4GTIVDE"}}, {"foreignKey": {"collection": "mention", "id": "W4BE746W"}}], "projects": [{"foreignKey": {"id": "what-works-when-for-whom", "collection": "project"}}, {"foreignKey": {"id": "evidence", "collection": "project"}}, {"foreignKey": {"id": "bridging-the-gap", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "utwente", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jvdzwaan"}, {"primaryKey": {"id": "noodles", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T15:21:10Z", "brandName": "Noodles", "bullets": "- Enables scientists to execute and restart parallel workflows by readable and easily maintainable Python code\n- Helps to scale computations in Python with complex dependencies to a parallel environment\n- No need to leave the comfort of Python: Noodles is a thin layer, unobtrusively handling complexity of a concurrent environment.\n", "conceptDOI": "10.5281/zenodo.595714", "contributors": [{"foreignKey": {"collection": "person", "id": "j.hidding"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "b.weel"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "v.hees"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "f.zapata"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "h.spreeuw"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.borgdorff"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.ridder"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "b.vanwerkhoven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "a.kuzniar"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://noodles.readthedocs.io/en/latest/index.html", "repositoryURLs": {"github": ["https://github.com/NLeSC/noodles"]}, "isFeatured": true, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "Often, a computer program can be sped up by executing parts of its code _in parallel_ (simultaneously), as opposed to _synchronously_ (one part after another).\n\nA simple example may be where you assign two variables, as follows\n\n``a = 2 * i``\n\nand\n\n``b = 3 * i``.\n\nEither statement is only dependent on ``i``, but whether you assign ``a`` before ``b`` or vice versa, does not matter for how your program works. Whenever this is the case, there is potential to speed up a program, because the assignment of ``a`` and ``b`` could be done in parallel, using multiple cores on your computer's CPU. Obviously, for simple assignments like\n\n``a = 2 * i``,\n\nthere is not much time to be gained, but what if ``a`` is the result of a time-consuming function, e.g. \n\n``a = very_difficult_function(i)``?\n\nAnd what if your program makes many calls to that function, e.g. \n\n``list_of_a = [very_difficult_function(i) for i in list_of_i]``?\n\nThe potential speed-up could be tremendous.\n\nSo, parallel execution of computer programs is great for improving performance, but how do you tell the computer which parts should be executed in parallel, and which parts should be executed synchronously? How do you identify the order in which to execute each part, since the optimal order may be different from the order in which the parts appear in your program. These questions quickly become nearly impossible to answer as your program grows and changes during development. Because of this, many developers accept the slow execution of their program only because it saves them from the headaches associated with keeping track of which parts of their program depend on which other parts.\n\nEnter Noodles.\n\nNoodles is a Python package that can automatically construct a _callgraph_ for a given Python program, listing exactly which parts depend on which parts. Moreover, Noodles can subsequently use the callgraph to execute code in parallel\non your local machine using multiple cores. If you so choose, you can even configure Noodles such that it will execute the code remotely, for example on a big compute node in a cluster computer.", "shortStatement": "Task-based parallel programming model in Python that offers the same intuitive interface when running complex workflows on your laptop or on large computer clusters. ", "slug": "noodles", "tags": ["Workflow technologies", "High performance computing"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "pyxenon", "collection": "software"}}, {"foreignKey": {"id": "xenon", "collection": "software"}}, {"foreignKey": {"id": "xenon-grpc", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "2NGMHSIL"}}, {"foreignKey": {"collection": "mention", "id": "BNT9AA3G"}}, {"foreignKey": {"collection": "mention", "id": "5ZU254AF"}}, {"foreignKey": {"collection": "mention", "id": "KVJH2CMM"}}], "projects": [{"foreignKey": {"id": "computational-chemistry-made-easy", "collection": "project"}}, {"foreignKey": {"id": "fast-open-source-simulator-of-low-energy-scattering-of-charged-particles-in", "collection": "project"}}, {"foreignKey": {"id": "estep", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "ochre", "collection": "software"}, "createdAt": "2017-11-14T13:30:36Z", "updatedAt": "2018-12-05T14:54:02Z", "brandName": "ochre", "bullets": "* Train character-based language models/LSTMs for OCR post-correction\n* Ready to use workflows for data preprocessing, training correction models, doing the post-correction, and analyzing (remaining) errors\n* Compare (corrected) OCR text to the gold standard based on character error rate (CER), word error rate (WER), and order independent word error rate\n* Analyze OCR errors on the word level\n* Discover OCR post-correction data sets", "conceptDOI": "10.0000/FIXME", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "j.vanderzwaan", "collection": "person"}, "isContactPerson": true}], "getStartedURL": "https://github.com/KBNLresearch/ochre", "repositoryURLs": {"github": ["https://github.com/KBNLresearch/ochre"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "Ochre is experimental software for cleaning up text with OCR mistakes. The software was developed to investigate whether character-based language models can be used to remove OCR mistakes. In addition, ochre provides functionality to analyze the kinds of OCR mistakes in a corpus. This enables researchers to compare different OCR post-correction methods and find out what kinds of mistakes they are good at solving.", "shortStatement": "A tool to clean up text generated by OCR using individual words as well as their context.", "slug": "ochre", "tags": ["Text analysis & natural language processing", "Machine learning"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "nlppln", "collection": "software"}}], "mentions": [{"foreignKey": {"id": "5X79PWRC", "collection": "mention"}}, {"foreignKey": {"id": "PRK6WS62", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "deep-learning-ocr-post-correction", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "kb", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jvdzwaan"}, {"primaryKey": {"id": "octseg", "collection": "software"}, "createdAt": "2017-11-16T15:55:35Z", "updatedAt": "2018-10-16T14:07:59Z", "brandName": "OCTSEG", "bullets": "* The retinal layers and the blood vessels of retinal OCT scans can be segmented\n* Automated segmentation of 6 prominent retinal layers:  the inner limiting membrane, outer nerve fiber layer boundary, and retinal pigment epithelium\n* Automated segmentation of the blood vessel positions on circular scans and batch processing of circular scans and manual correction of possible segmentation errors\n* Visualization of the data and the segmentation results, including enface views and thickness maps\n* Export of the segmentation results to CSV text files \n* Includes segmentation of phantom images\n* Successfully used in \"A Lightpath for Optical Coherence Tomography Imaging\" project", "conceptDOI": "10.5281/zenodo.1464025", "contributors": [{"foreignKey": {"id": "5ae85e6f0bd42f30d8877d4b", "collection": "person"}, "isContactPerson": false, "affiliations": []}, {"foreignKey": {"collection": "person", "id": "e.ranguelova"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/OCTSegmentation", "repositoryURLs": {"github": ["https://github.com/NLeSC/OCTSegmentation"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["MATLAB"], "readMore": null, "shortStatement": "Analyze retinal optical coherence tomography images.", "slug": "octseg", "tags": ["Image processing"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "elboyran"}, {"primaryKey": {"id": "omuse", "collection": "software"}, "createdAt": "2017-11-16T14:00:44Z", "updatedAt": "2018-11-27T15:23:24Z", "brandName": "OMUSE", "bullets": "* provides an easy-to-use environment for numerical experiments in the climate sciences\n* interfaces and couples simulation codes in an Python framework\n* allows researchers and students formulate intricate numerical experiments in simple python scripts\n* runs on local machines, supercomputers and on distributed computing resources", "conceptDOI": "10.5281/zenodo.809335", "contributors": [{"foreignKey": {"collection": "person", "id": "i.pelupessy"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "b.vanwerkhoven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "g.vandenoord"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://bitbucket.org/omuse/omuse/", "repositoryURLs": {"github": []}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "Fortran", "C", "Java", "C++"], "readMore": null, "shortStatement": "A simple Python environment to interface and couple oceanographic and other earth system model codes.", "slug": "omuse", "tags": ["Multi-scale & multi model simulations", "High performance computing"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"id": "XMIAFCN7", "collection": "mention"}}, {"foreignKey": {"id": "JWN2EPPJ", "collection": "mention"}}, {"foreignKey": {"id": "Y3KLFFCQ", "collection": "mention"}}, {"foreignKey": {"id": "YHSYEYXW", "collection": "mention"}}, {"foreignKey": {"id": "AZFY2HJ3", "collection": "mention"}}, {"foreignKey": {"id": "A3HXQY59", "collection": "mention"}}, {"foreignKey": {"id": "3ZZ3PB3I", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "abc-muse", "collection": "project"}}, {"foreignKey": {"id": "primavera", "collection": "project"}}, {"foreignKey": {"id": "towards-large-scale-cloud-resolving-climate-simulations", "collection": "project"}}, {"foreignKey": {"id": "ewatercycle-ii", "collection": "project"}}, {"foreignKey": {"id": "stochastic-multiscale-climate-models", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "leiden-university", "collection": "organization"}}, {"foreignKey": {"id": "uu", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "online-behaviour-machine-learning", "collection": "software"}, "createdAt": "2017-11-14T12:28:17Z", "updatedAt": "2018-11-26T12:38:48Z", "brandName": "Hercules", "bullets": "* support for machine learning experiments for researchers\n* data conversion for tweet data in project Automated Analysis of Online Behaviour on Social Media\n* handles data format used in this project (csv)\n* used for two scientific papers\n", "conceptDOI": "10.5281/zenodo.1045198", "contributors": [{"foreignKey": {"collection": "person", "id": "e.tjongkimsang"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/online-behaviour/machine-learning", "repositoryURLs": {"github": ["https://github.com/online-behaviour/machine-learning"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "In the project Automated Analysis of Online Behaviour on Social Media researchers wanted to find out what the intention was of tweets from politicians and political journalists. For this purpose they collected recent tweets from these two groups from Twitter and analysed these with machine learning software trained on older tweets which were labeled by humans. This software package contains the software for collecting and analyzing the tweets.", "shortStatement": "Retrieve recent tweets from certain users and classify them with machine learning", "slug": "online-behaviour-machine-learning", "tags": ["Text analysis & natural language processing", "Machine learning"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "finding-journalists", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "SGICAUIE"}}, {"foreignKey": {"collection": "mention", "id": "UW2RZD97"}}, {"foreignKey": {"collection": "mention", "id": "6HR2GJVP"}}, {"foreignKey": {"collection": "mention", "id": "WQYQ7LDM"}}], "projects": [{"foreignKey": {"id": "automated-analysis-of-online-behaviour-on-social-media", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "university.of.groningen", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "osmium", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-27T16:13:29Z", "brandName": "Osmium", "bullets": "* Uses Xenon to copy files and run executables on different storage systems and batch schedulers\n* Copies input files from your application server to the scheduler location and the result files back\n* To prevent polling for the job status, osmium can push status updates to your application server\n* Used in production to run jobs locally and on grid infrastructure", "conceptDOI": "10.5281/zenodo.1065435", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.borgdorff"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/osmium", "repositoryURLs": {"github": ["https://github.com/NLeSC/osmium"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "Start, stop and monitor applications remotely via a HTTP interface.", "slug": "osmium", "tags": ["High performance computing"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "chemical-informatics-for-metabolite-identification-and-biochemical-network", "collection": "project"}}, {"foreignKey": {"id": "dynaslum", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "palmetto-position-lucene-wikipedia", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2017-12-14T14:49:07Z", "brandName": "Palmetto position storing Lucene index of Dutch Wikipedia", "bullets": null, "conceptDOI": "10.5281/zenodo.46377", "contributors": [], "getStartedURL": null, "repositoryURLs": {"github": []}, "isFeatured": false, "isPublished": false, "license": [], "programmingLanguage": [], "readMore": null, "shortStatement": null, "slug": "palmetto-position-lucene-wikipedia", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": []}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "pattyanalytics", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-26T12:44:03Z", "brandName": "PattyAnalytics", "bullets": "* Place an object (dense but small point cloud) on a drive map (sparse point cloud with large extent)\n* Rotate, scale, and translate the object to absolute dimenstion (meters, lat/lon)\n* Read and write LAS files", "conceptDOI": "10.5281/zenodo.597210", "contributors": [{"foreignKey": {"collection": "person", "id": "j.attema"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.buitinck"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.borgdorff"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/PattyAnalytics", "repositoryURLs": {"github": ["https://github.com/NLeSC/PattyAnalytics"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "This library builds on Python bindings from the [python-pcl package](https://github.com/NLeSC/PattyAnalytics), which in turn uses the state of the art [Point Cloud Library](http://pointclouds.org/). This allows us to scale up to large point clouds, while keeping good performance via optional GPU acceleration.", "shortStatement": "Library for aligning and scaling one point cloud to an other.", "slug": "pattyanalytics", "tags": ["Big data"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "mapping-the-via-appia-in-3d", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "pattydata", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T14:55:34Z", "brandName": "PattyData", "bullets": "- FIXME\n- FIXME\n- FIXME", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "e.ranguelova"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "r.goncalves"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "r.vanharen"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/PattyData", "repositoryURLs": {"github": ["https://github.com/NLeSC/PattyData"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Data Management scripts for the Via Appia 3D GIS.", "slug": "pattydata", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "pattyvis", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2017-12-14T15:44:56Z", "brandName": "Via Appia Visualization", "bullets": "* A 3D interactive web application for archeology\n* Visualizes LiDAR data and Structure-From-Motion data as well as extensive meta-information.\n* Explore an extensive Archeology dataset from the comfort of your own home.\n", "conceptDOI": "10.5281/zenodo.597175", "contributors": [{"foreignKey": {"collection": "person", "id": "m.vanmeersbergen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "m.kuzak"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "b.vanwerkhoven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "p.bos"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/PattyVis", "repositoryURLs": {"github": ["https://github.com/NLeSC/pattyvis"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript"], "readMore": null, "shortStatement": "A web application which visualizes the point clouds and additional data gathered in the Via Appia project with  WebGL.", "slug": "pattyvis", "tags": ["Visualization"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "ahn2webviewer", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "MNDGRNKC"}}, {"foreignKey": {"collection": "mention", "id": "UNS4C36F"}}, {"foreignKey": {"collection": "mention", "id": "CI23NGIP"}}, {"foreignKey": {"collection": "mention", "id": "H4FPUCX9"}}, {"foreignKey": {"collection": "mention", "id": "IK2FKWQG"}}, {"foreignKey": {"collection": "mention", "id": "ZL7HWNDP"}}, {"foreignKey": {"collection": "mention", "id": "PPCP5SX7"}}, {"foreignKey": {"collection": "mention", "id": "AQAG27RN"}}, {"foreignKey": {"collection": "mention", "id": "99M8X7FJ"}}, {"foreignKey": {"collection": "mention", "id": "TS9ESAPQ"}}, {"foreignKey": {"collection": "mention", "id": "BWEWKL4D"}}, {"foreignKey": {"collection": "mention", "id": "DAZSQRHG"}}, {"foreignKey": {"collection": "mention", "id": "WRXCJSQJ"}}, {"foreignKey": {"collection": "mention", "id": "2R4LQFXU"}}, {"foreignKey": {"collection": "mention", "id": "Q8UCUHRS"}}, {"foreignKey": {"collection": "mention", "id": "AYA588GK"}}, {"foreignKey": {"collection": "mention", "id": "XQ8ZACT7"}}, {"foreignKey": {"collection": "mention", "id": "8E7X47N7"}}, {"foreignKey": {"collection": "mention", "id": "XYAN8393"}}, {"foreignKey": {"collection": "mention", "id": "USBRF89L"}}], "projects": [{"foreignKey": {"id": "mapping-the-via-appia-in-3d", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "pidimehs-library", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-11-26T12:47:50Z", "brandName": "PIDIMEHS library", "bullets": "* Showcase of interactive queries and visualization of textual data using ElasticSearch in Python for Digital Humanities\n* Query and summarize language usage from large textual databases, apply advanced relevance filtering, visualize trends over time", "conceptDOI": "10.5281/zenodo.1462286", "contributors": [{"foreignKey": {"collection": "person", "id": "p.bos"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.buitinck"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://bitbucket.org/egpbos/pidilib", "repositoryURLs": {"github": []}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "Showcases a diachronic analysis of the Dutch Royal Library's newspaper archive, answering questions about Dutch 20th century cultural and political segregation. Combines Pandas, Jupyter Notebooks and other PyData stack tools with ElasticSearch.", "shortStatement": "Showcases a diachronic analysis of the Dutch Royal Library's newspaper archive.", "slug": "pidimehs-library", "tags": ["Visualization", "Text analysis & natural language processing", "Real time data analysis", "Big data"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "texcavator", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "F74VT8VW"}}, {"foreignKey": {"collection": "mention", "id": "RVKZ4SCA"}}], "projects": [{"foreignKey": {"id": "pidimehs", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "university.of.groningen", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "potreeconverter", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T14:50:29Z", "brandName": "PotreeConverter", "bullets": "- FIXME\n- FIXME\n- FIXME", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/potree/PotreeConverter", "repositoryURLs": {"github": ["https://github.com/potree/PotreeConverter"]}, "isFeatured": false, "isPublished": false, "license": ["BSD-2-Clause"], "programmingLanguage": ["C++"], "readMore": null, "shortStatement": "Generate multi-resolution octree data structures as required by Potree-based renderers.", "slug": "potree-converter", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "pycoeman", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T14:48:26Z", "brandName": "pycoeman", "bullets": "- FIXME\n- FIXME\n- FIXME", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/pycoeman", "repositoryURLs": {"github": ["https://github.com/NLeSC/pycoeman"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Python toolkit for executing command-line commands.", "slug": "pycoeman", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "pymicmac", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T14:43:58Z", "brandName": "pymicmac", "bullets": "- FIXME\n- FIXME\n- FIXME", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/ImproPhoto/pymicmac", "repositoryURLs": {"github": ["https://github.com/ImproPhoto/pymicmac"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "A Python interface for MicMac workflow execution and distributed computing tools.", "slug": "pymicmac", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "python-pcl", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-09-26T08:49:04Z", "brandName": "python-pcl", "bullets": "* Point clouds are accessible as Numpy arrays\n* Loading and saving of (possibly colored) point clouds\n* Registration and boundary detection", "conceptDOI": "10.5281/zenodo.1435460", "contributors": [{"foreignKey": {"collection": "person", "id": "j.attema"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.buitinck"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.borgdorff"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/python-pcl", "repositoryURLs": {"github": ["https://github.com/NLeSC/python-pcl"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "C++"], "readMore": "The library was written for use in the Via Appia project; it is based on the work [here](https://github.com/strawlab/python-pcl).\nExample usage and support for the common LAS format can be found in the [PattyAnalytics](https://github.com/NLeSC/PattyAnalytics) repository.\n", "shortStatement": "Use the industry-standard Point Cloud Library from within Python.", "slug": "python-pcl", "tags": ["Big data", "High performance computing"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "mapping-the-via-appia-in-3d", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "pyxenon", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-26T12:54:30Z", "brandName": "PyXenon", "bullets": "- Provide easy access to compute and storage resources\n- A Python interface for Xenon\n\n", "conceptDOI": "10.5281/zenodo.595727", "contributors": [{"foreignKey": {"collection": "person", "id": "j.borgdorff"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.hidding"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://pyxenon.readthedocs.io/en/latest/", "repositoryURLs": {"github": ["https://github.com/NLeSC/pyxenon"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Python wrapper for the Xenon programming interface to various compute and storage resources.", "slug": "pyxenon", "tags": [], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "xenon", "collection": "software"}}, {"foreignKey": {"id": "xenon-grpc", "collection": "software"}}], "mentions": [], "projects": [{"foreignKey": {"id": "estep", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "qmflows", "collection": "software"}, "createdAt": "2017-11-14T12:07:56Z", "updatedAt": "2018-02-08T13:10:25Z", "brandName": "QMflows", "bullets": "* Automation of quantum chemistry simulations  for  scientists\n*  Input generation, molecular manipulation, tasks execution and data extraction for  quantum chemistry simulations\n* Interoperable between different quantum chemistry software\n\n\n", "conceptDOI": "10.5281/zenodo.1045522", "contributors": [{"foreignKey": {"collection": "person", "id": "f.zapata"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.ridder"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.hidding"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/SCM-NV/qmflows", "repositoryURLs": {"github": ["https://github.com/SCM-NV/qmflows"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "This library tackles the construction and efficient execution of computational chemistry workflows. This allows researchers to use massively parallel compute environments in an easy manner and focus on interpretation of scientific data rather than on tedious job submission procedures and manual data processing.", "shortStatement": "Construction and efficient execution of computational chemistry workflows.", "slug": "qmflows", "tags": ["Multi-scale & multi model simulations", "Workflow technologies"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "noodles", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "5S2WDXGF"}}, {"foreignKey": {"collection": "mention", "id": "5ZU254AF"}}, {"foreignKey": {"collection": "mention", "id": "KVJH2CMM"}}, {"foreignKey": {"collection": "mention", "id": "YTP6F3XH"}}, {"foreignKey": {"collection": "mention", "id": "2NGMHSIL"}}], "projects": [{"foreignKey": {"id": "computational-chemistry-made-easy", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "qtl-tableminer", "collection": "software"}, "createdAt": "2017-11-14T13:17:46Z", "updatedAt": "2019-02-21T19:24:07Z", "brandName": "QTLTableMiner++", "bullets": "* Provides command-line access to Quantitative Trait Loci commonly reported in tables\n* Makes these data available for queries in machine-readable formats\n* Aids in further data re-use and integration with other types of biological data", "conceptDOI": "10.5281/zenodo.1193639", "contributors": [{"affiliations": [{"foreignKey": {"id": "wur", "collection": "organization"}}], "foreignKey": {"id": "5ae85e6f0bd42f30d8877d47", "collection": "person"}, "isContactPerson": true}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "a.kuzniar", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/candYgene/QTM", "repositoryURLs": {"github": ["https://github.com/candYgene/QTM"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java", "SQL"], "readMore": null, "shortStatement": "Search open-access articles for genes associated with traits and make these data increasingly FAIR.", "slug": "qtl-tableminer", "tags": ["Text analysis & natural language processing", "Inter-operability & linked data"], "testimonials": [{"text": "An excellent tool to streamline the tedious but critical QTL data curation works. I highly value its usefulness to the research community.", "person": "Anonymous reviewer"}], "related": {"software": [], "mentions": [{"foreignKey": {"id": "RRSU2C9D", "collection": "mention"}}, {"foreignKey": {"collection": "mention", "id": "YKISRDC9"}}, {"foreignKey": {"id": "9BUZ7286", "collection": "mention"}}, {"foreignKey": {"collection": "mention", "id": "MXM5JHM7"}}, {"foreignKey": {"id": "X7NG2ZGP", "collection": "mention"}}, {"foreignKey": {"collection": "mention", "id": "M2M5QEKW"}}, {"foreignKey": {"id": "4LAB5TYA", "collection": "mention"}}, {"foreignKey": {"id": "74JN8IE9", "collection": "mention"}}, {"foreignKey": {"id": "S9CQLE77", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "prediction-of-candidate-genes-for-traits-using-interoperable-genome-annotat", "collection": "project"}}, {"foreignKey": {"id": "odex4all", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "wur", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "arnikz"}, {"primaryKey": {"id": "recipy", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T11:58:26Z", "brandName": "recipy", "bullets": "* Keep track of what code you ran to generate results (e.g., graphs or data)\n* Add a single statement to enable provenance tracking in your Python script\n* Search your runs using a command line interface or GUI\n* Customize provenance tracking for each project", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d51"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "university.of.southampton", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/recipy/recipy", "repositoryURLs": {"github": ["https://github.com/recipy/recipy"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "Imagine the situation: You\u2019ve written some wonderful Python code which produces a beautiful graph as an output. You save that graph, naturally enough, as graph.png. You run the code a couple of times, each time making minor modifications. You come back to it the next week/month/year. Do you remember how you created that graph? What input data? What version of your code? Frustratingly, the answer will often be 'no'. Of course, you then waste lots of time trying to work out how you created it, or even give up and never use it in that journal paper that will win you a Nobel Prize\u2026\n\nReciPy (from recipe and python) is a Python module that will save you from this situation! (Although it can\u2019t guarantee that your paper will win a Nobel Prize!) With the addition of a single line of code to the top of your Python files, ReciPy will log each run of your code to a database, keeping track of the input files, output files and the version of your code, and then let you query this database to find out how you actually did create graph.png.", "shortStatement": "Effortless provenance tracking in Python", "slug": "recipy", "tags": ["Optimized data handling", "Inter-operability & linked data"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "regis", "collection": "software"}, "createdAt": "2017-11-16T14:24:02Z", "updatedAt": "2018-09-25T14:58:57Z", "brandName": "ReGIS", "bullets": "* Provides a virtual laboratory for scientists wanting to explore spatial data\n* Upload and display your GIS data on the map\n* Allows for exploring theoretical scenarios using different model settings\n* Allows for visual storytelling on maps, e.g. the evolution of urban environments under a policy", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "b.weel"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "m.vanmeersbergen"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "e.tjongkimsang"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "r.bakhshi"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "d.vankuppevelt"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "w.kouw"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "m.devos"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/ReGIS-org/regis-v2", "repositoryURLs": {"github": ["https://github.com/ReGIS-org/regis-v2"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "Java", "TypeScript", "YAML"], "readMore": null, "shortStatement": "A virtual laboratory for researchers and urban planning officials to visualize, analyze and explore spatial data and model results.", "slug": "regis", "tags": ["Visualization", "High performance computing"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "common-sense", "collection": "software"}}], "mentions": [], "projects": [{"foreignKey": {"id": "estep", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "rig", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T11:52:57Z", "brandName": "Rig", "bullets": "- FIXME\n- FIXME\n- FIXME\n- FIXME\n", "conceptDOI": "10.0000/FIXME", "contributors": [{"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "w.vanhage"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "o.rubi"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.buitinck"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/nlesc-sherlock/Rig", "repositoryURLs": {"github": ["https://github.com/nlesc-sherlock/Rig"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "JavaScript"], "readMore": null, "shortStatement": "Big data cleaning toolkit", "slug": "rig", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "root-conda-recipes", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T11:49:52Z", "brandName": "ROOT-conda-recipes", "bullets": "- build CERN ROOT binaries and its dependencies\n- has Python 3 support\n- provides a Pythonic interface (pandas DataFrames) to the ROOT I/O format", "conceptDOI": "10.5281/zenodo.47512", "contributors": [{"foreignKey": {"collection": "person", "id": "d.remenska"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://legacy.gitbook.com/book/nlesc/cern-root-conda-recipes/details", "repositoryURLs": {"github": ["https://github.com/NLeSC/root-conda-recipes"]}, "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Conda recipes for building CERN ROOT binaries and its dependencies.", "slug": "root-conda-recipes", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "sagecal", "collection": "software"}, "createdAt": "2017-11-14T12:28:17Z", "updatedAt": "2018-11-26T13:30:54Z", "brandName": "Sagecal", "bullets": "Sagecal supports all source models including points, Gaussians and Shapelets. Distributed calibration using MPI and consensus optimization is enabled. Tools to build/restore sky models are included. Works on a wide range of platforms, from personal computers to supercomputer clusters.\n\n* Sagecal provides calibration solutions for radio-interferometric data\n* Sagecal calibrates large sets of visibility data\n* Sagecal provides a solution for large datasets which need to be calibrated across tens of GPU-accelerated compute nodes for many directions on the sky\n* Works for datasets with thousands of channels\n* GPU accelerated\n* Distributed calibration across many compute nodes\n* Provides calibration solutions for hundreds of directions on the sky simultaneously", "conceptDOI": "10.5281/zenodo.1051168", "contributors": [{"foreignKey": {"collection": "person", "id": "f.diblen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "h.spreeuw", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "astron", "collection": "organization"}}], "foreignKey": {"id": "a4121c61-4923-4b8f-ab5d-b45e47b9a84d", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "astron", "collection": "organization"}}], "foreignKey": {"id": "edda6362-a194-4443-bd93-c52b1ff8a5ae", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/nlesc-dirac/sagecal", "repositoryURLs": {"github": ["https://github.com/nlesc-dirac/sagecal"]}, "isFeatured": false, "isPublished": true, "license": ["GPL-2.0"], "programmingLanguage": ["C", "Python", "CUDA", "Java", "C++"], "readMore": null, "shortStatement": "Fast, memory efficient and GPU accelerated radio interferometric calibration program", "slug": "sagecal", "tags": ["Big data", "GPU", "High performance computing"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "AZFLQAD7"}}], "projects": [{"foreignKey": {"id": "dirac", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "astron", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "salient-region-detectors", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-05-23T11:40:08Z", "brandName": "SalientDetector-python", "bullets": "* Provides implementation of a competitive Data-driven Morphological Salient Region (DMSR) image detector for computer vision, biodiversity and other researchers who need to analyzable large amount of images for discovering or identifying objects or scenes\n* Highly repetitive detection  and visualization of salient regions in multiple structured images of the same scene or object of interest \n* Open-source and free code \n* Successfully applied to various tasks: automated determination weather images are from the same scene, marine mammals photo-identification, wood species classification from microscopy images, etc. \n* DMSR shows invariance to affine geometric image transformations as well as to photo-metric transformations such as blur and lighting \n* DMSR gives better results than the popular MSER region detector", "conceptDOI": "10.5281/zenodo.1042643", "contributors": [{"foreignKey": {"collection": "person", "id": "d.vankuppevelt"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "e.ranguelova"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/SalientDetector-python/blob/master/README.md", "repositoryURLs": {"github": ["https://github.com/NLeSC/SalientDetector-python"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "E. Ranguelova, \"A Salient Region Detector for structured images,\" \n2016 IEEE/ACS 13th International Conference of Computer Systems and Applications (AICCSA),\nAgadir, 2016, pp. 1-8.\ndoi: 10.1109/AICCSA.2016.7945643", "shortStatement": "If you want to automate your object detection or photo-identification image tasks in an easy way with free open-source software, the SalientDetector-Python is the tool for you", "slug": "salient-detector-python", "tags": ["Image processing"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "salientdetector-matlab", "collection": "software"}}, {"foreignKey": {"id": "salientdescriptor-matlab-imvip", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "K9AS8XX8"}}, {"foreignKey": {"collection": "mention", "id": "TPLTCBC2"}}, {"foreignKey": {"collection": "mention", "id": "2LG6TPQX"}}], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "salientdescriptor-matlab-imvip", "collection": "software"}, "createdAt": "2017-11-14T13:13:32Z", "updatedAt": "2018-06-20T09:34:25Z", "brandName": "SalientDescriptor-matlab", "bullets": "* Provides implementation of a competitive Shape and Moment Invariant (SMI) descriptor  for computer vision, biodiversity and other researchers who need to match images for identifying objects or scenes\n* Simple and scalable description and matching of salient regions in multiple structured images of the same scene or object of interest \n* Open-source code for researchers who are used to MATLAB\n* Successfully applied to automated determination weather images are from the same scene for the Oxford (VGG) and OxFrei benchmarks\n* SMI gives better results than the popular SURF descriptor on MSER regions with less computations", "conceptDOI": "10.5281/zenodo.831663", "contributors": [{"foreignKey": {"collection": "person", "id": "e.ranguelova"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/SalientDescriptor-matlab/blob/master/README.md", "repositoryURLs": {"github": ["https://github.com/NLeSC/SalientDescriptor-matlab"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["MATLAB"], "readMore": "Ranguelova, E., Local Shape and Moment Invariant Descriptor for Structured Images, \nProceedings of the 19th Irish Machine Vision and Image Processing (IMVIP) conference, \nMaynooth, Ireland, 2017, pp. 245-248", "shortStatement": "If you need to automate your image matching tasks for the purposes of object detection or photo-identification in an easy way, the SalientDescriptor-matlab is right for you", "slug": "salient-descriptor-matlab", "tags": ["Image processing"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "salientdetector-matlab", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "V7ZDZNXT"}}], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "salientdetector-matlab", "collection": "software"}, "createdAt": "2017-11-14T13:13:32Z", "updatedAt": "2018-06-20T09:34:39Z", "brandName": "SalientDetector-matlab", "bullets": "* Provides MATLAB implementation of a competitive Data-driven Morphological Salient Region (DMSR) image detector for computer vision, biodiversity and other researchers who need to analyzable large amount of images for discovering or identifying objects or scenes\n* Highly repetitive detection  and visualization of salient regions in multiple structured images of the same scene or object of interest \n* Open-source code for researchers who are used to MATLAB\n* Successfully applied to various tasks: automated determination whether images are from the same scene, marine mammals photo-identification, wood species classification from microscopy images, etc. \n* DMSR shows invariance to affine geometric image transformations as well as to photo-metric transformations such as blur and lighting \n* DMSR gives better results than the popular MSER region detector", "conceptDOI": "10.5281/zenodo.1042639", "contributors": [{"foreignKey": {"collection": "person", "id": "e.ranguelova"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/SalientDetector-matlab/blob/master/README.md", "repositoryURLs": {"github": ["https://github.com/NLeSC/SalientDetector-matlab"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["MATLAB"], "readMore": "E. Ranguelova, \"A Salient Region Detector for structured images,\" \n2016 IEEE/ACS 13th International Conference of Computer Systems and Applications (AICCSA),\nAgadir, 2016, pp. 1-8.\ndoi: 10.1109/AICCSA.2016.7945643", "shortStatement": "If you want to automate object detection or image photo-identification tasks in an easy way with open MATLAB software, the SalientDetector-MATLAB is right for you", "slug": "salient-detector-matlab", "tags": ["Image processing"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "salient-region-detectors", "collection": "software"}}, {"foreignKey": {"id": "salientdescriptor-matlab-imvip", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "K9AS8XX8"}}, {"foreignKey": {"collection": "mention", "id": "TPLTCBC2"}}, {"foreignKey": {"collection": "mention", "id": "2LG6TPQX"}}], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "scriptcwl", "collection": "software"}, "createdAt": "2017-11-14T13:10:51Z", "updatedAt": "2018-03-26T15:28:53Z", "brandName": "scriptcwl", "bullets": "* Create CWL workflows without learning CWL or YAML\n* Make workflows by programming \n* Design workflows interactively in Jupyter notebooks", "conceptDOI": "10.5281/zenodo.1050358", "contributors": [{"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "b.andela"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.veen"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "b.devries"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "r.vanharen"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "a.vanderploeg"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/nlesc/scriptcwl", "repositoryURLs": {"github": ["https://github.com/nlesc/scriptcwl"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "Scriptcwl is a Python package for creating Common Workflow Language (CWL) workflows by writing a Python script instead of manually typing YAML or using a GUI. To work with scriptcwl, you need to give it a bunch of CWL CommandLineTools. Then you subsequently specify the workflow inputs, steps, and workflow outputs, and save the result to a file. This can be done interactively in a Jupyter notebook. A scriptcwl script to generate a workflow provides a concise and transparent representation of your workflow; one that is much more readable than YAML. ", "shortStatement": "Create CWL workflows by writing a simple Python script.", "slug": "scriptcwl", "tags": ["Workflow technologies"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "4SXMEX3U"}}], "projects": [{"foreignKey": {"id": "what-works-when-for-whom", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "utwente", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "sfm", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-09-27T09:59:41Z", "brandName": "Structure from Motion", "bullets": "- pipeline to construct 3D point clouds from a set of 2D images", "conceptDOI": "10.5281/zenodo.594751", "contributors": [{"foreignKey": {"collection": "person", "id": "n.drost"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.spaaks"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.maassen"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/structure-from-motion", "repositoryURLs": {"github": ["https://github.com/NLeSC/structure-from-motion"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "C++"], "readMore": null, "shortStatement": "Construct 3D pointclouds from a set of 2D images", "slug": "structure-from-motion", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "sherlock-emma", "collection": "software"}, "createdAt": "2017-11-16T14:46:53Z", "updatedAt": "2018-10-15T09:56:29Z", "brandName": "Emma", "bullets": "* It is designed for users deploying Spark and DockerSwarm clusters in a cloud infra-structure.\n* It helps the user to prepare cloud virtual machines\n* The provision of machines is done with Ansible, an automation tool for IT infra-structure. \n* It provides command line access to the users to install the required libraries and systems, configure them, start/stop services, add new modules for Jupyter notebooks, and even update the firewall", "conceptDOI": "10.5281/zenodo.996294", "contributors": [{"foreignKey": {"collection": "person", "id": "n.drost"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.attema"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "r.goncalves", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/nlesc-sherlock/emma#emma", "repositoryURLs": {"github": ["https://github.com/nlesc-sherlock/emma"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["YAML"], "readMore": "Emma is an open-source project to create a platform for development of applications for Spark and DockerSwarm clusters. The platform runs on an infra-structure composed by virtual machines that must be reachable by SSH. The machines are either cloud virtual machines or Vagrant machines. The latter tool allows the platform to be simulated on a local machine, i.e. in a local development environment.\n\nOnce the machines are prepared, the servers are provisioned using Ansible, an automation tool for IT infra-structure. Ansible playbooks\nare used to create a storage layer, processing layer, and JupyterHub services. The storage layer offers two flavors of storage, file-base by GlusterFS and Hadoop Distributed File System (HDFS), and object-based using Minio. The processing layer has a Apache Spark cluster and a Docker Swarm sharing the storage instances. \n\nWith Ansible we are able to deploy a platform with the same features at different locations, such as local cluster, national infra-structure, or even a commercial cloud provider. Such a feature allows us to have tool-provenance for easily repeatability of experiments between scientists.", "shortStatement": "Emma is a project to create a platform for development of application for Spark and DockerSwarm clusters.", "slug": "emma", "tags": ["Big data"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "high-spatial-resolution-phenological-modelling-at-continental-scales", "collection": "project"}}, {"foreignKey": {"id": "eecolidar", "collection": "project"}}], "organizations": []}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "shifting-concepts-through-time", "collection": "software"}, "createdAt": "2017-11-16T16:13:30Z", "updatedAt": "2018-11-27T15:48:20Z", "brandName": "ShiCo", "bullets": " * Provides historians with a tool for exploring concept shifts\n * Explores changes on words related to a seed word\n * It provides a unique way of using word2vec technology over different time intervals\n", "conceptDOI": "10.5281/zenodo.1187089", "contributors": [{"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/ShiCo", "repositoryURLs": {"github": ["https://github.com/NLeSC/ShiCo"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": "ShiCo is a tool for visualizing time shifting concepts. We refer to a concept as the set of words which are related to a given seed word. ShiCo uses a set of semantic models (word2vec) spanning a number of years to explore how concepts change over time -- words related to a given concept at time t=0 may differ from the words related to the same concept at time t=n.", "shortStatement": "A visualization that shows how the meaning we attach to a given concept shifts over time.", "slug": "shifting-concepts-through-time", "tags": ["Visualization", "Text analysis & natural language processing"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "HWD3XJ4S"}}, {"foreignKey": {"collection": "mention", "id": "E9LCF79I"}}], "projects": [{"foreignKey": {"id": "mining-shifting-concepts-through-time-shico", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "uu", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "siga-py", "collection": "software"}, "createdAt": "2017-11-14T13:17:46Z", "updatedAt": "2018-11-27T15:49:59Z", "brandName": "SIGA.py", "bullets": "* An easy-to-use command-line tool for bioinformaticians\n* Transforms genome annotations in GFF files into RDF graphs using a config file\n* Supports different GFF versions and RDF serializations (formats)\n* Used in combination with RDF stores or Linked Data platforms", "conceptDOI": "10.5281/zenodo.1076437", "contributors": [{"foreignKey": {"collection": "person", "id": "a.kuzniar"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "r.bakhshi"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/candYgene/siga", "repositoryURLs": {"github": ["https://github.com/candYgene/siga"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "A command line tool to transform genome annotations in GFF format into the semantically interoperable RDF format.", "slug": "siga-py", "tags": ["Inter-operability & linked data"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "linked-data-platform-for-plant-breeding-genomics", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "MXM5JHM7"}}, {"foreignKey": {"collection": "mention", "id": "T76UXCBC"}}], "projects": [{"foreignKey": {"id": "prediction-of-candidate-genes-for-traits-using-interoperable-genome-annotat", "collection": "project"}}, {"foreignKey": {"id": "odex4all", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "wur", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "spot", "collection": "software"}, "createdAt": "2017-11-14T13:10:51Z", "updatedAt": "2018-07-02T09:41:55Z", "brandName": "SPOT", "bullets": "* Visualize and interact with multidimensional data using a variety of linked charts\n* Drag and drop, no need for any programming\n* Load your own data, or connect to a database\n* Store and share your sessions\n* Can be used online as a web app or as a standalone desktop application", "conceptDOI": "10.5281/zenodo.1003345", "contributors": [{"foreignKey": {"collection": "person", "id": "j.attema"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "f.diblen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://nlesc.github.io/spot", "repositoryURLs": {"github": ["https://github.com/NLeSC/spot", "https://github.com/NLeSC/spot-desktop-app"]}, "isFeatured": true, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["JavaScript", "HTML"], "readMore": "With SPOT, you can gain insight into multi-dimensional datasets in just a few\nclicks. It requires no programming at all, everything is drag and drop. SPOT is\ndesigned to feel quick and responsive, even for data sets containing millions of\nrecords, and it works across a wide variety of platforms (PC, smartphone,\ntablet), operating systems (Windows, Linux, Mac), and browsers (Firefox, Google\nChrome, Safari).", "shortStatement": "SPOT is an interactive visualization tool for multi-dimensional data. It allows quick analysis of complex datasets and easy identification of  correlations between variables.", "slug": "spot", "tags": ["Visualization", "Big data"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "HI7ZAHTI"}}], "projects": [{"foreignKey": {"id": "idark", "collection": "project"}}, {"foreignKey": {"id": "aa-alert", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "astron", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "storyteller", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-26T15:37:53Z", "brandName": "StoryTeller", "bullets": "* Visual Analytics for text data with rich connections\n* Able to show connections between entities and storylines\n* Interconnected graphs and visualizations with many filtering options\n* Successfully used in multiple Humanities projects", "conceptDOI": "10.5281/zenodo.996323", "contributors": [{"foreignKey": {"collection": "person", "id": "m.vanmeersbergen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://nlesc.github.io/UncertaintyVisualization/", "repositoryURLs": {"github": ["https://github.com/NLeSC/UncertaintyVisualization"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "JavaScript"], "readMore": null, "shortStatement": "StoryTeller is a web application for visual analysis of textual data which can show you the connections between storylines, participants and other entities in complex humanities data.", "slug": "storyteller", "tags": ["Visualization"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "HKMM6BGF"}}, {"foreignKey": {"id": "YNMWYUDW", "collection": "mention"}}, {"foreignKey": {"id": "B9A5AB5G", "collection": "mention"}}, {"foreignKey": {"id": "5BR6QUH5", "collection": "mention"}}, {"foreignKey": {"id": "4BT84776", "collection": "mention"}}, {"foreignKey": {"id": "GIA2VJE3", "collection": "mention"}}, {"foreignKey": {"id": "2Y56IUR9", "collection": "mention"}}, {"foreignKey": {"id": "EXE348TZ", "collection": "mention"}}, {"foreignKey": {"id": "2KH9BFYW", "collection": "mention"}}, {"foreignKey": {"id": "8LRX6AL8", "collection": "mention"}}, {"foreignKey": {"id": "MDSMCRPY", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "visualizing-uncertainty-and-perspectives", "collection": "project"}}, {"foreignKey": {"id": "from-sentiment-mining-to-mining-embodied-emotions", "collection": "project"}}, {"foreignKey": {"id": "biographynet", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "surf-eds-one-button-compute", "collection": "software"}, "createdAt": "2017-11-14T13:37:17Z", "updatedAt": "2018-05-23T15:03:28Z", "brandName": "One button compute", "bullets": "* Provides a web interface to run a CWL workflow on each input file\n* Downloads input files from remote storage, runs a CWL workflows and uploads the output files to remote storage\n* The user needs to supply the input files and workflow, he/she does not need to care about how the workflow is run\n", "conceptDOI": "10.5281/zenodo.1033816", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "n.drost"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/surf-eds/one-button-compute", "repositoryURLs": {"github": ["https://github.com/surf-eds/one-button-compute"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Web application for running a CWL workflow on a bunch of files.", "slug": "one-button-compute", "tags": ["Workflow technologies", "Optimized data handling"], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "realizing-the-full-potential-of-the-dutch-e-infrastructure", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "surfsara", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "texcavator", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-11-26T15:51:13Z", "brandName": "Texcavator", "bullets": "* Create word cloud and time line visualizations of large text corpora\n* Download search results for offline processing\n* Based on Elasticsearch\n* Used for educational purposes", "conceptDOI": "10.5281/zenodo.1442760", "contributors": [{"foreignKey": {"collection": "person", "id": "j.vanderzwaan"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d55"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"id": "uu", "collection": "organization"}}]}], "getStartedURL": "https://github.com/UUDigitalHumanitieslab/texcavator", "repositoryURLs": {"github": ["https://github.com/UUDigitalHumanitieslab/texcavator"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "JavaScript"], "readMore": null, "shortStatement": "Texcavator is a search engine and text mining application for creating word cloud and time line visualizations of large text corpora.", "slug": "texcavator", "tags": ["Text analysis & natural language processing", "Visualization"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "4MZQ7YKZ"}}, {"foreignKey": {"collection": "mention", "id": "F4SEMGRI"}}, {"foreignKey": {"collection": "mention", "id": "FFEHAJN7"}}, {"foreignKey": {"collection": "mention", "id": "5NJLF3XA"}}, {"foreignKey": {"collection": "mention", "id": "I4FNCUR3"}}, {"foreignKey": {"collection": "mention", "id": "KS4ZY73G"}}, {"foreignKey": {"collection": "mention", "id": "NPZRYZY3"}}], "projects": [{"foreignKey": {"id": "texcavator", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "uu", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "the-crowdtruth-framework", "collection": "software"}, "createdAt": "2017-11-16T13:37:30Z", "updatedAt": "2017-12-14T14:56:55Z", "brandName": "The CrowdTruth Framework", "bullets": " * Provides an interface to analyse crowdsourced annotations\n * Collect gold standard data via CrowdFlower and MechanicalTurk\n * Simplifies gold standard data collection and analysis\n ", "conceptDOI": null, "contributors": [{"foreignKey": {"collection": "person", "id": "c.martinez"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "", "repositoryURLs": {"github": ["https://github.com/CrowdTruth/CrowdTruth"]}, "isFeatured": false, "isPublished": false, "license": [], "programmingLanguage": ["PHP", "Python"], "readMore": null, "shortStatement": "The CrowdTruth Framework implements an approach to machine-human computing for collecting annotation data on text, images, sounds and videos. The approach is focussed specifically on collecting gold standard data for training and evaluation of cognitive computing systems.", "slug": "the-crowdtruth-framework", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "AU977B5V"}}], "projects": [{"foreignKey": {"id": "dr.-watson", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "Unknown"}, {"primaryKey": {"id": "twinl-website-code", "collection": "software"}, "createdAt": "2017-11-14T12:28:17Z", "updatedAt": "2018-05-23T11:17:35Z", "brandName": "Twiqs", "bullets": "* search facility for tweets for users interested in tweet statistics\n* implements webserver and communication with Hadoop server with tweets\n* access to tweet statistics (more detailed than Twitter)\n* dozens of research papers and at least 1 PhD thesis used this service", "conceptDOI": "10.5281/zenodo.1045248", "contributors": [{"foreignKey": {"collection": "person", "id": "e.tjongkimsang"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/twinl/website", "repositoryURLs": {"github": ["https://github.com/twinl/website"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java", "Perl", "JavaScript"], "readMore": "Many researchers want to analyse tweets but find it to collect large numbers of messages and analyze these. The website twiqs.nl was created to support research based on Dutch tweets. The websites offers a search function that can be applied to tweets dating back to 2010. Twitter does not allow the text of tweets to be offered as a download.  Instead the website offers summaries of the tweets in graphs, on maps, word clouds and pie diagrams. Since it creation in 2012, the website has been used by many researchers and common people to test ideas about word usage in Dutch tweets.\n\nThis software package contains the software used by the website twiqs.nl.", "shortStatement": "Software behind the web server twiqs.nl, which has provided free access to statistics about Dutch tweets since 2010", "slug": "twinl-website-code", "tags": ["Text analysis & natural language processing", "Visualization", "Big data"], "testimonials": [{"affiliation": "ictnieuws", "person": "Jan Lepeltak", "text": "biedt prachtige mogelijkheden voor onderzoeksvragen in de les"}], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "J8BTLL3D"}}, {"foreignKey": {"collection": "mention", "id": "VQ2IF5J8"}}, {"foreignKey": {"collection": "mention", "id": "IUNSVSCX"}}, {"foreignKey": {"collection": "mention", "id": "7LN8NYL3"}}, {"foreignKey": {"collection": "mention", "id": "EH3RVLTZ"}}, {"foreignKey": {"collection": "mention", "id": "J4IFBZAK"}}, {"foreignKey": {"collection": "mention", "id": "JTAPT4FU"}}, {"foreignKey": {"collection": "mention", "id": "DR4ZKYG6"}}, {"foreignKey": {"collection": "mention", "id": "BR7SNZMN"}}, {"foreignKey": {"collection": "mention", "id": "J3X6GRA9"}}, {"foreignKey": {"collection": "mention", "id": "XSUTAJW6"}}, {"foreignKey": {"collection": "mention", "id": "WTQNHUZ5"}}, {"foreignKey": {"collection": "mention", "id": "ZUCE2N3J"}}, {"foreignKey": {"collection": "mention", "id": "HTSD448T"}}, {"foreignKey": {"collection": "mention", "id": "E6IBMWQ3"}}, {"foreignKey": {"collection": "mention", "id": "J2V5FJKS"}}], "projects": [{"foreignKey": {"id": "twinl", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "surfsara", "collection": "organization"}}, {"foreignKey": {"id": "radboud.university.nijmegen", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "wadpac-ggir", "collection": "software"}, "createdAt": "2017-11-23T16:28:11Z", "updatedAt": "2019-03-10T12:38:49Z", "brandName": "GGIR", "bullets": "* GGIR is an R-package to process and analysis multi-day data collected with wearable raw data accelerometers for physical activity and sleep research.\n* GGIR uses this information to describe the data per day of measurement or per measurement, including estimates of physical activity, inactivity, and sleep. As part of the pipeline GGIR performs automatic signal calibration, detection of sustained abnormally high values, detection of sensor non-wear and calculation of average magnitude acceleration based on a variety of metrics.\n* GGIR is the only open source licensed software that provides a full pipeline for both physical activity and sleep analyses, with a high freedom for the user to configure the analyses to their needs.\n* The package has been used for domain science in 70+ publications, and is supported by 8 methodological publications.", "conceptDOI": "10.5281/zenodo.1051064", "contributors": [{"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d56"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "56908ca3-56b8-400f-a09e-529a4717eec9", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d57"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "96b74a2b-767a-4267-bf6e-413c22b66949", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d58"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "eaa31adf-bcfb-4502-8318-1b1c094a7132", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d59"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "9d4bfc7c-9290-4574-8148-d1c7fefe2011", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d5a"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "162c4b5b-bc50-4b47-a3d4-e510856af594", "collection": "organization"}}, {"foreignKey": {"id": "eaa31adf-bcfb-4502-8318-1b1c094a7132", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d5b"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "8bfa28a7-284a-46eb-8118-c60d08ffe6ef", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "v.hees"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://cran.r-project.org/web/packages/GGIR/vignettes/GGIR.html", "repositoryURLs": {"github": ["https://github.com/wadpac/GGIR"]}, "isFeatured": true, "isPublished": true, "license": ["LGPL-2.0"], "programmingLanguage": ["R"], "readMore": "The package has been developed and tested for binary data from GENEActiv and GENEA devices, .csv-export data from Actigraph devices, and .cwa and .wav-format data from Axivity. These devices are currently widely used in research on human daily physical activity.\n\nA list of publications using GGIR can be found here: https://github.com/wadpac/GGIR/wiki/Publication-list\n\nThe package vignette which gives a general introduction can be found here: https://cran.r-project.org/web/packages/GGIR/vignettes/GGIR.html.\n", "shortStatement": "Converts raw data from wearables into insightful reports for researchers investigating human daily physical activity and sleep.", "slug": "ggir", "tags": ["Big data"], "testimonials": [{"affiliation": "Institute of Myology, Paris, France", "person": "Damien Bachasson", "text": "Thank you @vtvanhees for your work and support on the #GGIRpackage "}, {"text": "The GGIR R package has been used extensively with GENEActiv, ActiGraph, and Axivity data and has grown organically to become the application of choice for many researchers using raw acceleration data to study not only PA and sedentary time, but also sleep.", "person": "Prof. Stuart Fairclough", "affiliation": "Edgehill University, Ormskirk, UK"}], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "5Y4XZEWA"}}, {"foreignKey": {"collection": "mention", "id": "6AYD5WSU"}}, {"foreignKey": {"collection": "mention", "id": "8XRT2F52"}}, {"foreignKey": {"collection": "mention", "id": "9XWR44HK"}}, {"foreignKey": {"collection": "mention", "id": "BES7R6QT"}}, {"foreignKey": {"collection": "mention", "id": "CV5V3E3Q"}}, {"foreignKey": {"collection": "mention", "id": "DRLPNEBL"}}, {"foreignKey": {"collection": "mention", "id": "FEUWZ6IC"}}, {"foreignKey": {"collection": "mention", "id": "FF9ZHZYJ"}}, {"foreignKey": {"collection": "mention", "id": "HEWKJKLG"}}, {"foreignKey": {"collection": "mention", "id": "MTCWASE8"}}, {"foreignKey": {"collection": "mention", "id": "R67T3BS5"}}, {"foreignKey": {"id": "S9YIZCVH", "collection": "mention"}}, {"foreignKey": {"collection": "mention", "id": "TJF9ANES"}}, {"foreignKey": {"collection": "mention", "id": "V3E5HU9P"}}, {"foreignKey": {"collection": "mention", "id": "Z9CMFFLE"}}, {"foreignKey": {"collection": "mention", "id": "4EHR36PZ"}}, {"foreignKey": {"collection": "mention", "id": "5UM2SSLS"}}, {"foreignKey": {"collection": "mention", "id": "6FNX3J2Z"}}, {"foreignKey": {"collection": "mention", "id": "72P93V4M"}}, {"foreignKey": {"collection": "mention", "id": "77BH3GHM"}}, {"foreignKey": {"collection": "mention", "id": "8CCWFZJK"}}, {"foreignKey": {"collection": "mention", "id": "8MAW66KY"}}, {"foreignKey": {"collection": "mention", "id": "AIRUZBW5"}}, {"foreignKey": {"collection": "mention", "id": "CI5BZXJ6"}}, {"foreignKey": {"collection": "mention", "id": "DTPFXUDA"}}, {"foreignKey": {"collection": "mention", "id": "EML2WW4L"}}, {"foreignKey": {"collection": "mention", "id": "EWMMN5FZ"}}, {"foreignKey": {"collection": "mention", "id": "HPNI3KID"}}, {"foreignKey": {"collection": "mention", "id": "I4B9YQ5R"}}, {"foreignKey": {"collection": "mention", "id": "J6V4LUMZ"}}, {"foreignKey": {"collection": "mention", "id": "LLZ3RCDA"}}, {"foreignKey": {"collection": "mention", "id": "PAG5HZ4U"}}, {"foreignKey": {"collection": "mention", "id": "QSKUUUY9"}}, {"foreignKey": {"collection": "mention", "id": "QZNZ87FA"}}, {"foreignKey": {"collection": "mention", "id": "SW966TBV"}}, {"foreignKey": {"collection": "mention", "id": "TTPV7GZ6"}}, {"foreignKey": {"collection": "mention", "id": "USMT5XPS"}}, {"foreignKey": {"collection": "mention", "id": "X5HYYYCN"}}, {"foreignKey": {"collection": "mention", "id": "ZGN5HH5J"}}, {"foreignKey": {"id": "JTITRTS6", "collection": "mention"}}, {"foreignKey": {"id": "CN57RX5J", "collection": "mention"}}, {"foreignKey": {"id": "HKUWRD9S", "collection": "mention"}}, {"foreignKey": {"id": "AU63HNAN", "collection": "mention"}}, {"foreignKey": {"id": "2S3AS3IY", "collection": "mention"}}, {"foreignKey": {"id": "N8JD3YGH", "collection": "mention"}}, {"foreignKey": {"id": "XNFSE92Y", "collection": "mention"}}, {"foreignKey": {"id": "MCM6U9T5", "collection": "mention"}}, {"foreignKey": {"id": "VA7W8GZX", "collection": "mention"}}, {"foreignKey": {"id": "EZY39HWD", "collection": "mention"}}, {"foreignKey": {"id": "STENMWG8", "collection": "mention"}}, {"foreignKey": {"id": "XSV5CR68", "collection": "mention"}}, {"foreignKey": {"id": "RX7ZR9QS", "collection": "mention"}}, {"foreignKey": {"id": "YKQW5HLV", "collection": "mention"}}, {"foreignKey": {"id": "ME3PDHB8", "collection": "mention"}}, {"foreignKey": {"id": "D83AQH2Z", "collection": "mention"}}, {"foreignKey": {"id": "ZU3N8AVI", "collection": "mention"}}, {"foreignKey": {"id": "HWY835JL", "collection": "mention"}}, {"foreignKey": {"id": "9RZKRS54", "collection": "mention"}}, {"foreignKey": {"id": "DUVTEZLZ", "collection": "mention"}}, {"foreignKey": {"id": "8YK8GC33", "collection": "mention"}}, {"foreignKey": {"id": "X5HYYYCN", "collection": "mention"}}, {"foreignKey": {"id": "EG2GGEYB", "collection": "mention"}}, {"foreignKey": {"id": "HTWQD779", "collection": "mention"}}, {"foreignKey": {"id": "X8BS5UUH", "collection": "mention"}}, {"foreignKey": {"id": "KXYKCKBU", "collection": "mention"}}, {"foreignKey": {"id": "IS658T9T", "collection": "mention"}}, {"foreignKey": {"id": "C2JDK4BB", "collection": "mention"}}, {"foreignKey": {"id": "QF993T86", "collection": "mention"}}, {"foreignKey": {"id": "F7D2GPJM", "collection": "mention"}}, {"foreignKey": {"id": "NC3HX388", "collection": "mention"}}, {"foreignKey": {"id": "5B6YDKEF", "collection": "mention"}}, {"foreignKey": {"id": "T6QP7U5S", "collection": "mention"}}, {"foreignKey": {"id": "ZDLJSU6G", "collection": "mention"}}, {"foreignKey": {"id": "4RHWUXK8", "collection": "mention"}}, {"foreignKey": {"id": "XJU5A4ES", "collection": "mention"}}, {"foreignKey": {"id": "AA39ZIQK", "collection": "mention"}}, {"foreignKey": {"id": "INR7Z7GD", "collection": "mention"}}, {"foreignKey": {"id": "Z6JEWNDH", "collection": "mention"}}, {"foreignKey": {"id": "6MVC8YFZ", "collection": "mention"}}, {"foreignKey": {"id": "IS658T9T", "collection": "mention"}}, {"foreignKey": {"id": "FTGAM2UF", "collection": "mention"}}, {"foreignKey": {"id": "M4YIT5UV", "collection": "mention"}}, {"foreignKey": {"id": "96483G92", "collection": "mention"}}, {"foreignKey": {"id": "MJPYI88U", "collection": "mention"}}, {"foreignKey": {"id": "GXD33X2I", "collection": "mention"}}, {"foreignKey": {"id": "E5VZUAVD", "collection": "mention"}}, {"foreignKey": {"id": "2JGD5UP2", "collection": "mention"}}, {"foreignKey": {"id": "PA6TE4SW", "collection": "mention"}}, {"foreignKey": {"id": "GLKVRBLN", "collection": "mention"}}, {"foreignKey": {"id": "WNB8YKFH", "collection": "mention"}}, {"foreignKey": {"id": "N9I24CTG", "collection": "mention"}}, {"foreignKey": {"id": "LHWJSLTF", "collection": "mention"}}, {"foreignKey": {"id": "XMVW9SVW", "collection": "mention"}}, {"foreignKey": {"id": "Q4XYFYGL", "collection": "mention"}}, {"foreignKey": {"id": "EDYRSNG7", "collection": "mention"}}, {"foreignKey": {"id": "9HK443LQ", "collection": "mention"}}, {"foreignKey": {"id": "W2IY6C4T", "collection": "mention"}}, {"foreignKey": {"id": "KMHWXLQE", "collection": "mention"}}, {"foreignKey": {"id": "N8VK7E3R", "collection": "mention"}}, {"foreignKey": {"id": "VH37RXJU", "collection": "mention"}}], "projects": [{"foreignKey": {"id": "genetics-of-sleep-patterns", "collection": "project"}}, {"foreignKey": {"id": "classifying-activity-types", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "9d4bfc7c-9290-4574-8148-d1c7fefe2011", "collection": "organization"}}, {"foreignKey": {"id": "96b74a2b-767a-4267-bf6e-413c22b66949", "collection": "organization"}}, {"foreignKey": {"id": "162c4b5b-bc50-4b47-a3d4-e510856af594", "collection": "organization"}}, {"foreignKey": {"id": "8bfa28a7-284a-46eb-8118-c60d08ffe6ef", "collection": "organization"}}, {"foreignKey": {"id": "eaa31adf-bcfb-4502-8318-1b1c094a7132", "collection": "organization"}}, {"foreignKey": {"id": "56908ca3-56b8-400f-a09e-529a4717eec9", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "vincentvanhees"}, {"primaryKey": {"id": "xenon", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2019-02-27T14:07:41Z", "brandName": "Xenon", "bullets": "* Provides an easy-to-use interface for distributed computing developers \n* Enables the use of different file transfer protocols and scheduling systems on remote machines \n* No need to learn and implement many different APIs\n* Successfully used in many eScience tools and projects", "conceptDOI": "10.5281/zenodo.597993", "contributors": [{"foreignKey": {"collection": "person", "id": "j.maassen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "n.drost"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "r.vannieuwpoort"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.borgdorff"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "c.meijer"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "b.vanwerkhoven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "5ae85e700bd42f30d8877d5c"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, {"foreignKey": {"collection": "person", "id": "j.spaaks"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/xenon-middleware/Xenon", "repositoryURLs": {"github": ["https://github.com/NLeSC/Xenon"]}, "isFeatured": true, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": "Many applications use remote storage and compute resources. To do so, they need\nto include code to interact with the scheduling systems and file transfer\nprotocols used on those remote machines.\n\nUnfortunately, many different scheduler systems and file transfer protocols\nexist, often with completely different programming interfaces. This makes it\ndifficult for applications to switch to a different system or support multiple\nremote systems simultaneously.\n\nXenon solves this problem by providing a single programming interface to many\ndifferent types of remote resources. As a result, changing from one scheduler to\nanother, or from one file transfer protocol to another, becomes a matter of\nchanging just a few lines of code. This is obviously much cheaper in time and\nmoney than developing, debugging, and maintaining new code that implements the\nsame logic you had before, but for a different scheduler or a different file\ntransfer protocol.\n", "shortStatement": "If you are using remote machines to do your computations, and don\u2019t feel like learning and implementing many different APIs, Xenon is the tool for you.", "slug": "xenon", "tags": ["Big data", "Optimized data handling", "High performance computing"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "pyxenon", "collection": "software"}}, {"foreignKey": {"id": "xenon-cli", "collection": "software"}}, {"foreignKey": {"id": "xenon-grpc", "collection": "software"}}, {"foreignKey": {"id": "36b8b46e-2e67-44ad-879d-f8151d253329", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "XRA6XBNB"}}, {"foreignKey": {"collection": "mention", "id": "4YFQQKF2"}}, {"foreignKey": {"id": "ZDCPSCGU", "collection": "mention"}}, {"foreignKey": {"collection": "mention", "id": "RJSMU2ZG"}}, {"foreignKey": {"collection": "mention", "id": "IKDX5IJ2"}}, {"foreignKey": {"collection": "mention", "id": "QDDQUR8S"}}], "projects": [{"foreignKey": {"id": "chemical-informatics-for-metabolite-identification-and-biochemical-network", "collection": "project"}}, {"foreignKey": {"id": "abc-muse", "collection": "project"}}, {"foreignKey": {"id": "amuse", "collection": "project"}}, {"foreignKey": {"id": "realizing-the-full-potential-of-the-dutch-e-infrastructure", "collection": "project"}}, {"foreignKey": {"id": "esalsa", "collection": "project"}}, {"foreignKey": {"id": "mapping-the-via-appia-in-3d", "collection": "project"}}, {"foreignKey": {"id": "visualizing-uncertainty-and-perspectives", "collection": "project"}}, {"foreignKey": {"id": "googling-the-cancer-genome", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "xenon-cli", "collection": "software"}, "createdAt": "2017-11-14T13:13:32Z", "updatedAt": "2018-12-05T10:15:48Z", "brandName": "Xenon command line interface", "bullets": "* Provides an easy-to-use command line interface for distributed computing developers \n* Makes the main methods of the Xenon library accessible on the command line\n* Low threshold introduction to the features of Xenon library\n* No programming required to use\n* Used in training material of Xenon library", "conceptDOI": "10.5281/zenodo.597603", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.spaaks"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/xenon-cli", "repositoryURLs": {"github": ["https://github.com/NLeSC/xenon-cli"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "A command line interface for the Xenon library that allows you to use remote machines to do your computations.", "slug": "xenon-cli", "tags": ["High performance computing"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "HZM5Y5HK"}}, {"foreignKey": {"collection": "mention", "id": "4C4VALLZ"}}, {"foreignKey": {"collection": "mention", "id": "6AZEKMLQ"}}, {"foreignKey": {"collection": "mention", "id": "5HC7I86M"}}], "projects": [{"foreignKey": {"id": "googling-the-cancer-genome", "collection": "project"}}, {"foreignKey": {"id": "prediction-of-candidate-genes-for-traits-using-interoperable-genome-annotat", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "arnikz"}, {"primaryKey": {"id": "xenon-grpc", "collection": "software"}, "createdAt": "2017-11-14T13:13:32Z", "updatedAt": "2018-11-27T16:10:04Z", "brandName": "Xenon gRPC server", "bullets": "* Provides an easy-to-use interface for distributed computing developers who want to use a different language than Java\n* Xenon gRPC wraps the Xenon library in a server\n* Retains the Xenon library API as much as possible\n* Allows to the Xenon Java library to be called from C++, Python, Go, Ruby, C#, Node.js, Objective-C and PHP (any language supported by gRPC) using generated clients.", "conceptDOI": "10.5281/zenodo.1043481", "contributors": [{"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "a.vanderploeg"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.maassen"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/xenon-grpc", "repositoryURLs": {"github": ["https://github.com/NLeSC/xenon-grpc"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java"], "readMore": null, "shortStatement": "Run applications remotely via a gRPC interface.", "slug": "xenon-grpc", "tags": ["High performance computing"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "HZM5Y5HK"}}, {"foreignKey": {"collection": "mention", "id": "4C4VALLZ"}}, {"foreignKey": {"collection": "mention", "id": "6AZEKMLQ"}}, {"foreignKey": {"collection": "mention", "id": "5HC7I86M"}}], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jmaassen"}, {"primaryKey": {"id": "xtas", "collection": "software"}, "createdAt": "2017-11-10T14:12:55Z", "updatedAt": "2018-10-15T09:56:43Z", "brandName": "xtas", "bullets": "* easy access to numerous text processing and analysis tools\n* full support for Dutch and English\n* can use Elasticsearch for document storage\n* can be run as a service", "conceptDOI": "10.5281/zenodo.1436531", "contributors": [{"foreignKey": {"collection": "person", "id": "l.buitinck"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.veen"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "http://xtas.net/setup.html", "repositoryURLs": {"github": ["https://github.com/NLeSC/xtas"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Java", "Python"], "readMore": "xtas is a collection of natural language processing and text mining tools, brought together in a single software package with built-in distributed computing and support for the Elasticsearch document store.\n\nxtas functionality consists partly of wrappers for existing packages, with automatic installation of software and data; and partly of custom-built modules coming out of research. Currently offered are various parsers for Dutch and English (Alpino, CoreNLP, Frog, Semafor), named entity recognizers (Frog, Stanford and custom-built ones), a temporal expression tagger (Heideltime) and a sentiment tagger based on SentiWords.\n\nA basic installation of xtas works like a Python module. Built-in package management and a simple, uniform interface take away the hassle of installing, configuring and using many existing NLP tools.\n\nxtas\u2019s open architecture makes it possible to include custom code, run this in a distributed fashion and have it communicate with Elasticsearch to provide document storage and retrieval. ", "shortStatement": "the eXtensible Text Analysis Suite", "slug": "xtas", "tags": ["Text analysis & natural language processing"], "testimonials": [], "related": {"software": [], "mentions": [{"foreignKey": {"collection": "mention", "id": "AGIWSX9H"}}], "projects": [{"foreignKey": {"id": "spudisc", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "boatswain", "collection": "software"}, "createdAt": "2018-01-17T16:39:51Z", "updatedAt": "2018-06-20T09:19:47Z", "brandName": "boatswain", "bullets": "* Simplifies building each Docker container when you have a tree of dependencies\n\n", "conceptDOI": "10.5281/zenodo.1149010", "contributors": [{"foreignKey": {"collection": "person", "id": "b.weel"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.spaaks"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/NLeSC/boatswain", "repositoryURLs": {"github": ["https://github.com/NLeSC/boatswain"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Boatswain is a simple build system for docker images. It is especially useful when you have multiple docker images that depend on each other.", "slug": "boatswain", "tags": [], "testimonials": [], "related": {"software": [], "mentions": [], "projects": [{"foreignKey": {"id": "estep", "collection": "project"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "research-software-directory", "collection": "software"}, "createdAt": "2018-01-22T09:21:00Z", "updatedAt": "2019-02-27T14:09:02Z", "brandName": "Research Software Directory", "bullets": "- Works like a content management system tailored to software\n- Improves findability of software packages\n- Includes metadata to help search engines understand what a given software package is about\n- Harvests data from Zotero, Zenodo, GitHub, as well as other sources, and presents software packages within their social and scientific context\n- Promotes dissemination of software\n- Modular system that is meant to be customizable, e.g. with respect to branding, database schemas, an so on\n- Makes scientific impact visible in a qualitative way", "conceptDOI": "10.5281/zenodo.1154130", "contributors": [{"foreignKey": {"collection": "person", "id": "t.klaver"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "t.bakker"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "v.hees"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "a.mendrik"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.maassen"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.kulik"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "j.spaaks"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.ridder"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "w.vanhage"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "l.bogaardt"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}], "getStartedURL": "https://github.com/research-software-directory/research-software-directory", "repositoryURLs": {"github": ["https://github.com/research-software-directory/research-software-directory"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python", "TypeScript", "HTML", "Shell scripts", "YAML"], "readMore": "The Research Software Directory is a content management system that is tailored to software. \n\nThe idea is that institutes for whom research software is an important output, can run their own instance of the Research Software Directory. The system is designed to be flexible enough to allow for different data sources, database schemas, and so on. By default, the Research Software Directory is set up to collect data from GitHub, Zenodo, Zotero, as well as Medium blogs.\n\nFor each software package, a _product page_ can be created on the Research Software Directory if the software is deemed useful to others. While the content shown on the product page can be completely customized, by default it includes a _Mentions_ section, which can be used to characterize the context in which the software exists. The context may include links to scientific papers, but is certainly broader than that: for example, there may be links to web applications that demonstrate the use of the software, there may be links to videos on YouTube, tutorials on readthedocs.io or Jupyter notebooks, or there may be links to blog posts; really, anything that helps visitors decide if the software could be useful for them.\n\nThe Research Software Directory improves findability of software packages, partly because it provides metadata that helps search engines understand what the software is about, but more importantly because of the human centered text snippets that must be provided for each software package. After all, discovery of a software package is often not so much about finding it but knowing that you found it.\n\n", "shortStatement": "The Research Software Directory aims to promote the impact, the exchange and re-use of research software.", "slug": "research-software-directory", "tags": ["Visualization"], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "1b016e70-83c5-4dec-adde-46f16d4f6469", "collection": "software"}}, {"foreignKey": {"id": "cff-converter-python", "collection": "software"}}], "mentions": [{"foreignKey": {"collection": "mention", "id": "A4VM84DE"}}, {"foreignKey": {"collection": "mention", "id": "NDY56PVS"}}, {"foreignKey": {"id": "Z7KP8E6T", "collection": "mention"}}, {"foreignKey": {"id": "LH7N3HLN", "collection": "mention"}}, {"foreignKey": {"id": "BR69DREQ", "collection": "mention"}}, {"foreignKey": {"id": "EAH48DS3", "collection": "mention"}}, {"foreignKey": {"id": "QILHK2UV", "collection": "mention"}}, {"foreignKey": {"id": "6A432QWX", "collection": "mention"}}, {"foreignKey": {"id": "HPPWWJPS", "collection": "mention"}}, {"foreignKey": {"id": "X546X47C", "collection": "mention"}}, {"foreignKey": {"id": "7IF8G9SC", "collection": "mention"}}, {"foreignKey": {"id": "GEI4EA74", "collection": "mention"}}, {"foreignKey": {"id": "GZJ5CEKK", "collection": "mention"}}], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"primaryKey": {"id": "cff-converter-python", "collection": "software"}, "createdAt": "2018-03-20T10:55:38Z", "updatedAt": "2018-10-08T10:01:56Z", "brandName": "cffconvert", "bullets": "- command line tool written in Python\n- simple installation\n- read CFF files from GitHub URLs or local files\n- convert to BibTeX, EndNote, RIS, codemeta, plain JSON, or Zenodo JSON\n- validate the CFF against the schema", "conceptDOI": "10.5281/zenodo.1162057", "contributors": [{"foreignKey": {"collection": "person", "id": "j.spaaks"}, "isContactPerson": true, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "t.klaver"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"foreignKey": {"collection": "person", "id": "s.verhoeven"}, "isContactPerson": false, "affiliations": [{"foreignKey": {"collection": "organization", "id": "nlesc"}}]}, {"affiliations": [{"foreignKey": {"id": "a2b9ec98-32f0-42ad-8851-417c04a9d36b", "collection": "organization"}}], "foreignKey": {"id": "bc8f79d4-7621-4905-830f-b8839b04b21f", "collection": "person"}, "isContactPerson": false}], "getStartedURL": "https://github.com/citation-file-format/cff-converter-python", "repositoryURLs": {"github": ["https://github.com/citation-file-format/cff-converter-python"]}, "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "programmingLanguage": ["Python"], "readMore": null, "shortStatement": "Command line tool to convert CITATION.cff files to various formats used by reference managers such as Zotero and JabRef.", "slug": "cffconvert", "tags": [], "testimonials": [], "related": {"software": [{"foreignKey": {"id": "research-software-directory", "collection": "software"}}, {"foreignKey": {"id": "1b016e70-83c5-4dec-adde-46f16d4f6469", "collection": "software"}}], "mentions": [{"foreignKey": {"id": "XYUL4J3A", "collection": "mention"}}, {"foreignKey": {"id": "QILHK2UV", "collection": "mention"}}, {"foreignKey": {"id": "XA44RZ5E", "collection": "mention"}}, {"foreignKey": {"id": "28Y7MCJB", "collection": "mention"}}], "projects": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "a2b9ec98-32f0-42ad-8851-417c04a9d36b", "collection": "organization"}}]}, "createdBy": "Unknown", "updatedBy": "jspaaks"}, {"brandName": "sv-callers", "bullets": "* Enables comprehensive detection of structural variants (SVs) using multiple tools\n* Enables portable SV analyses using different HPC systems (e.g., GridEngine or Slurm clusters)\n* Supports both single- and paired-samples analyses in a parallel workflow\n* It's easy to use, deploy and extend with new tools", "conceptDOI": "10.5281/zenodo.1217111", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "a.kuzniar", "collection": "person"}, "isContactPerson": true}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "s.verhoeven", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "j.maassen", "collection": "person"}, "isContactPerson": false}], "createdAt": "2018-05-31T16:47:52Z", "createdBy": "arnikz", "getStartedURL": "https://github.com/GooglingTheCancerGenome/sv-callers/blob/master/README.md", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "f8cd16ce-528e-4be3-a9e4-446196e017af", "collection": "software"}, "programmingLanguage": ["Python", "Java"], "readMore": "This [Snakemake](https://snakemake.readthedocs.io/en/stable/)-based workflow combines several state-of-the-art tools (i.e. [Manta](https://github.com/Illumina/manta), [DELLY](https://github.com/dellytools/delly), [LUMPY](https://github.com/arq5x/lumpy-sv) and [GRIDSS](https://github.com/PapenfussLab/gridss)) for detecting structural variants (SVs) in whole genome sequencing data. The workflow is easy to use and to deploy on any Linux-based machine. In particular, the workflow supports automated software deployment, easy configuration and addition of new analysis tools as well as enables to scale from a single computer to different HPC clusters with minimal effort.", "related": {"mentions": [{"foreignKey": {"id": "6RT39N3L", "collection": "mention"}}, {"foreignKey": {"id": "LN85H5UH", "collection": "mention"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "c28890af-5a5c-47dd-8e3b-5666f8bdc1c8", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "googling-the-cancer-genome", "collection": "project"}}], "software": [{"foreignKey": {"id": "xenon-cli", "collection": "software"}}]}, "repositoryURLs": {"github": ["https://github.com/GooglingTheCancerGenome/sv-callers"]}, "shortStatement": "Highly portable parallel workflow for detecting structural variants in whole-genome sequences.", "tags": ["High performance computing", "Workflow technologies", "Big data"], "testimonials": [], "updatedAt": "2019-05-08T16:09:24Z", "updatedBy": "arnikz", "slug": "sv-callers"}, {"brandName": "xenon-flow", "conceptDOI": "10.0000/FIXME", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "b.weel", "collection": "person"}, "isContactPerson": true}, {"affiliations": [{"foreignKey": {"id": "41cf1db9-abf8-4fd0-93d5-8f0d69edc11a", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "j.borgdorff", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "n.drost", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "4dd90469-435b-46fd-9121-73535376742f", "collection": "organization"}}], "foreignKey": {"id": "41d8eea2-ecbf-4108-8f28-7f0168438ff7", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "s.verhoeven", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "j.maassen", "collection": "person"}, "isContactPerson": false}], "createdAt": "2018-06-27T09:44:27Z", "createdBy": "jspaaks", "getStartedURL": "https://github.com/NLeSC/xenon-flow", "isFeatured": false, "isPublished": false, "license": ["Apache-2.0"], "primaryKey": {"id": "36b8b46e-2e67-44ad-879d-f8151d253329", "collection": "software"}, "programmingLanguage": ["Java"], "readMore": "FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME ", "related": {"mentions": [], "organizations": [], "projects": [{"foreignKey": {"id": "bridging-the-gap", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/NLeSC/xenon-flow"]}, "shortStatement": "Run CWL workflows using Xenon through a REST API.", "tags": [], "testimonials": [], "updatedAt": "2018-06-29T12:41:18Z", "updatedBy": "jspaaks", "bullets": "FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME FIXME ", "slug": "xenon-flow"}, {"brandName": "Netherlands eScience Center Python Template", "bullets": "* Template for a basic Python project structure\n* Set up with testing and documentation\n* Comply to the software development guide", "conceptDOI": "10.5281/zenodo.1310752", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "j.vanderzwaan", "collection": "person"}, "isContactPerson": true}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "b.andela", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "b.vanwerkhoven", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "l.veen", "collection": "person"}, "isContactPerson": false}], "createdAt": "2018-07-12T11:35:30Z", "createdBy": "jvdzwaan", "getStartedURL": "https://github.com/NLeSC/python-template", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "1a5579c8-3457-4234-91a5-f168f562878f", "collection": "software"}, "programmingLanguage": ["Python"], "readMore": "When starting a new Python project, consider using this template. It provides a basic project structure, so you can spend less time setting up and configuring your new Python package, and comply with the software guide right from the start. The 'empty' Python package created with this template is set up with documentation and testing. A README specifying details about the project setup is also included in your new Python package.", "related": {"mentions": [{"foreignKey": {"id": "DQYQKKZ4", "collection": "mention"}}], "organizations": [], "projects": [], "software": []}, "repositoryURLs": {"github": ["https://github.com/NLeSC/python-template"]}, "shortStatement": "Spend less time setting up and configuring your new Python packages and comply with the Netherlands eScience Center Software Development Guide from the start.", "tags": [], "testimonials": [], "updatedAt": "2019-01-28T12:49:22Z", "updatedBy": "jvdzwaan", "slug": "nlesc-python-template"}, {"brandName": "cffinit", "bullets": "When you made some software and you want to include instructions on how to cite it, CITATION.cff files are the answer. However, sometimes it's tricky to ensure you write valid CFF. This tool helps mitigate that problem by generating the CFF text using a web form with form validation and user feedback.\n\n- authors can be rearranged\n- keywords can be rearranged\n- includes some automated checking/form validation with feedback to the user\n- compliant with http://www.yamllint.com/\n- compliant with Citation FIle Format specification v1.0.3\n- does not support the full CFF spec yet", "conceptDOI": "10.5281/zenodo.1404735", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "j.spaaks", "collection": "person"}, "isContactPerson": true}], "createdAt": "2018-08-28T12:09:51Z", "createdBy": "jspaaks", "getStartedURL": "https://citation-file-format.github.io/cff-initializer-javascript/", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "1b016e70-83c5-4dec-adde-46f16d4f6469", "collection": "software"}, "programmingLanguage": ["JavaScript"], "related": {"mentions": [{"foreignKey": {"id": "28Y7MCJB", "collection": "mention"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "projects": [], "software": [{"foreignKey": {"id": "cff-converter-python", "collection": "software"}}, {"foreignKey": {"id": "research-software-directory", "collection": "software"}}]}, "repositoryURLs": {"github": ["https://github.com/citation-file-format/cff-initializer-javascript"]}, "shortStatement": "A web form to initialize CITATION.cff files which you can use to include citation information into your software repository.", "tags": [], "testimonials": [], "updatedAt": "2018-11-27T15:59:02Z", "updatedBy": "jmaassen", "slug": "cffinit"}, {"brandName": "ESMValTool", "bullets": "* Facilitates the complex evaluation of ESMs and their simulations submitted to international Model Intercomparison Projects (e.g., CMIP).\n* Standardized model evaluation can be performed against observations, against other models or to compare different versions of the same model.\n* Wide scope: includes many diagnostics and performance metrics covering different aspects of the Earth System (dynamics, radiation, clouds, carbon cycle, chemistry, aerosol, sea-ice, etc.) and their interactions.\n* Well-established analysis: standard namelists reproduce specific sets of diagnostics or performance metrics that have demonstrated their importance in ESM evaluation in the peer-reviewed literature.\n* Broad documentation: user guide (Eyring et al., 2015); SPHINX; a log-file is written containing all the information of a specific call of the main script: creation date of running the script, version number, analyzed data (models and observations), applied diagnostics and variables, and corresponding references. This helps to increase the traceability and reproducibility of the results.\n* High flexibility: new diagnostics and more observational data can be easily added.\n* Multi-language support: Python, NCL, R... other open-source languages are possible.\n* CF/CMOR compliant: data from many different projects can be handled (CMIP, obs4mips, ana4mips, CCMI, CCMVal, AEROCOM, etc.). Routines are provided to CMOR-ize non-compliant data.\n* Integration in modeling workflows: for EMAC, NOAA-GFDL and NEMO, can be easily extended.\n", "conceptDOI": "10.17874/ac8548f0315", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "b.andela", "collection": "person"}, "isContactPerson": true}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "n.drost", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "f.diblen", "collection": "person"}, "isContactPerson": false}], "createdAt": "2018-10-01T11:24:00Z", "createdBy": "bouweandela", "getStartedURL": "https://www.esmvaltool.org", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "08588403-c74a-4b64-8d61-be013208eb0f", "collection": "software"}, "programmingLanguage": ["Python", "R", "YAML"], "readMore": "The Earth System Model eValuation Tool (ESMValTool) is a community diagnostics and performance metrics tool for the evaluation of Earth System Models (ESMs) that allows for routine comparison of single or multiple models, either against predecessor versions or against observations. The priority of the effort so far has been to target specific scientific themes focusing on selected Essential Climate Variables, a range of known systematic biases common to ESMs, such as coupled tropical climate variability, monsoons, Southern Ocean processes, continental dry biases and soil hydrology-climate interactions, as well as atmospheric CO2 budgets, tropospheric and stratospheric ozone, and tropospheric aerosols. The tool is being developed in such a way that additional analyses can easily be added. A set of standard namelists for each scientific topic reproduces specific sets of diagnostics or performance metrics that have demonstrated their importance in ESM evaluation in the peer-reviewed literature. The ESMValTool is a community effort open to both users and developers encouraging open exchange of diagnostic source code and evaluation results from the CMIP ensemble. This will facilitate and improve ESM evaluation beyond the state-of-the-art and aims at supporting such activities within the Coupled Model Intercomparison Project (CMIP) and at individual modeling centers. Ultimately, we envisage running the ESMValTool alongside the Earth System Grid Federation (ESGF) as part of a more routine evaluation of CMIP model simulations while utilizing observations available in standard formats (obs4MIPs) or provided by the user.", "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "8bee8809-f646-48a0-8581-07aa3cd61cc7", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "magic", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/ESMValGroup/ESMValTool"]}, "shortStatement": "The Earth System Model eValuation Tool is a community diagnostics and performance metrics tool for the evaluation of Earth System Models that allows for routine comparison of models and observations.", "tags": ["Workflow technologies", "Big data", "Visualization"], "testimonials": [], "updatedAt": "2018-11-26T15:58:07Z", "updatedBy": "jspaaks", "slug": "esmvaltool"}, {"brandName": "yatiml", "bullets": "- Lets you describe a document format/object model by defining Python classes\n- Checks YAML input against your format/model\n- Applies transformations that make the YAML file easier to read and write\n- Constructs Python objects from YAML in your format\n- Saves Python objects to YAML in your format", "conceptDOI": "10.5281/zenodo.1478048", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "l.veen", "collection": "person"}, "isContactPerson": true}], "createdAt": "2018-10-08T11:47:04Z", "createdBy": "jspaaks", "getStartedURL": "https://yatiml.readthedocs.io/en/latest/tutorial.html", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "1739d194-2719-460d-b87a-326232fc85b7", "collection": "software"}, "programmingLanguage": ["Python"], "readMore": "YAML-based file formats can be very handy, as YAML is easy to write by humans, and parsing support for it is widely available. Just read your YAML file into a document structure (a tree of nested dicts and lists), and manipulate that in your code.\n\nWhile this works fine for simple file formats, it does not scale very well to more complex file formats such as the Common Workflow Language (CWL) or the Multiscale Computing Language (yMCL). Manual error-checking is lots of work and error-prone, defaults are not set automatically (which is especially tricky if you have multiple nested optional objects), and the file format often ends up somewhat underspecified.\n\nFurthermore, a small collection of nested dicts and lists may work fine, but for more complex file formats, this becomes unwieldy and a set of objects is a better choice. Although it is not often used this way, YAML is actually a fully fledged object-to-text serialisation protocol. The Python yaml and ruamel.yaml libraries will actually construct objects for you, but the class names need to be put in the YAML file for that to work, which makes those files harder to read and write for humans.\n\nYAtiML is a helper library that helps address these issues. With YAtiML, you have easy-to-read YAML for the user, and easy-to-use objects for the programmer, with validation and automatic type recognition in between.", "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}, {"foreignKey": {"id": "vua", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "e-musc", "collection": "project"}}, {"foreignKey": {"id": "enhancing-protein-drug-binding-prediction", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/yatiml/yatiml"]}, "shortStatement": "Python library for YAML type inference, schema checking and syntactic sugar.", "tags": [], "testimonials": [], "updatedAt": "2018-11-05T15:28:28Z", "updatedBy": "LourensVeen", "slug": "yatiml"}, {"brandName": "JupyterLab dataset browser for THREDDS", "conceptDOI": "10.5281/zenodo.1241006", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "s.verhoeven", "collection": "person"}, "isContactPerson": true}], "createdAt": "2018-10-09T12:03:33Z", "createdBy": "sverhoeven", "getStartedURL": "https://github.com/eWaterCycle/jupyterlab_thredds", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "e9af79ab-c53c-477b-a4bd-4a74b4ae757c", "collection": "software"}, "programmingLanguage": ["Python", "TypeScript"], "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "tudelft", "collection": "organization"}}, {"foreignKey": {"id": "nlesc", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "ewatercycle-ii", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/eWaterCycle/jupyterlab_thredds"]}, "shortStatement": "A browser that allows you to include NetCDF data stored in THREDDS catalog into a Jupyter Notebook.", "tags": ["Optimized data handling", "Big data"], "testimonials": [{"text": "This seems really cool! Something similar could probably be developed for intake.", "person": "Ryan Abernathey", "affiliation": "Assistant professor of Earth and Environmental Sciences at Columbia University"}], "updatedAt": "2018-11-27T16:01:30Z", "updatedBy": "jmaassen", "slug": "jupyterlab-thredds", "bullets": "* Provides an easy way to select and use a dataset from a THREDDS catalog in a Jupyter notebook\n* Offers several ways to open a dataset in Python using graphical user interface instead of copy/pasting urls and having to figure out the right code snippet\n"}, {"brandName": "Experiment Launcher", "bullets": "* For software developers wanting to talk to a Swagger based webservice to generate and launch a Jupyter notebook based on parameters and a template\n* When the experiment launcher is combined with a frontend application like, the TerriaJS the end user is able click somewhere in the frontend and end up in a Jupyter notebook environment\n* Can be extended to have end points for different notebook types", "conceptDOI": "10.5281/zenodo.1453264", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "s.verhoeven", "collection": "person"}, "isContactPerson": true}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "b.weel", "collection": "person"}, "isContactPerson": false}], "createdAt": "2018-10-09T13:21:49Z", "createdBy": "sverhoeven", "getStartedURL": "https://github.com/eWaterCycle/experiment-launcher", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "1c05a9ce-be67-4f1d-8f3d-e6c41f21e457", "collection": "software"}, "programmingLanguage": ["Python"], "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "tudelft", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "ewatercycle-ii", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/eWaterCycle/experiment-launcher"]}, "shortStatement": "Generate and launch Jupyter notebooks for your users.", "tags": ["Workflow technologies"], "testimonials": [], "updatedAt": "2018-11-26T16:00:41Z", "updatedBy": "jspaaks", "slug": "experiment-launcher"}, {"brandName": "Satsense", "bullets": "- Provides a framework for performing land use classification on satellite images\n- Comes with easy to use Jupyter notebook examples\n- Provides an implementation of hand-crafted features commonly used for detecting deprived neighbourhoods in satellite images, like HoG, Lacunarity, NDXI, Pantex, Texton, SIFT\n- Will provide various metrics for measuring performance\n", "conceptDOI": "10.5281/zenodo.1463015", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "b.weel", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "e.ranguelova", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "b.andela", "collection": "person"}, "isContactPerson": true}], "createdAt": "2018-10-15T15:37:10Z", "createdBy": "bouweandela", "getStartedURL": "https://github.com/DynaSlum/satsense", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "dc2ae42c-9abc-4a46-9c37-4ef81e8fc2cb", "collection": "software"}, "programmingLanguage": ["Python"], "readMore": "Satsense is a Python library for land use classification, with a particular focus on deprived neighbourhood detection. However, many of the algorithms made available through Satsense can be applied in other domains. Detection of deprived neighbourhoods is a land use classification problem that is traditionally solved using hand crafted features like HoG, Lacunarity, NDXI, Pantex, Texton, and SIFT with very high resolution satellite images. One of the problems with assessing the performance of these kind of algorithms for this application, is that there is no easy to use open source reference implementation of such features, a problem that Satsense solves. In the future Satsense will also provide metrics to assess the performance. Satsense is built in a modular way which makes it easy to add your own hand-crafted feature or use deep learning instead of hand crafted features.", "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "uva", "collection": "organization"}}, {"foreignKey": {"id": "utwente", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "dynaslum", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/DynaSlum/satsense"]}, "shortStatement": "A Python library for land use classification based in satellite images.", "tags": ["Image processing", "Machine learning"], "testimonials": [], "updatedAt": "2018-11-27T16:01:58Z", "updatedBy": "jmaassen", "slug": "satsense"}, {"brandName": "cerulean", "bullets": "* Python 3 library for talking to HPC clusters and supercomputers\n* Copy files to and from remote machines\n* Start processes locally or through SSH\n* Manage jobs on a local or remote scheduler\n* Python 3 / SSH / SFTP / Slurm / Torque", "conceptDOI": "10.5281/zenodo.1478077", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "l.veen", "collection": "person"}, "isContactPerson": true}], "createdAt": "2018-11-05T14:51:39Z", "createdBy": "jspaaks", "getStartedURL": "https://cerulean.readthedocs.io/en/latest/", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "edeb3fbd-9b62-4207-a15e-a2942321f007", "collection": "software"}, "programmingLanguage": ["Python"], "readMore": "Cerulean is a Python 3 library for talking to HPC clusters and supercomputers. It lets you copy files between local and SFTP filesystems, it lets you start processes locally and remotely via SSH, and it lets you submit jobs to schedulers such as Slurm and Torque/PBS. The file access functions of Cerulean use a pathlib-like API, but unlike in pathlib, Cerulean supports remote file systems. That means that there is no longer just the local file system, but multiple file systems, and that Path objects have a particular file system that they are on. On High-Performance Computing machines, you don\u2019t run commands directly. Instead, you submit batch jobs to a scheduler, which will place them in a queue, and run them when everyone else in line before you is done. With Cerulean, you can submit jobs to a scheduler and track their progress, using a simple Python API.", "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "e-musc", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/MD-Studio/cerulean"]}, "shortStatement": "A Python 3 library for talking to HPC clusters and supercomputers.", "tags": [], "testimonials": [], "updatedAt": "2018-11-26T16:05:09Z", "updatedBy": "jspaaks", "slug": "cerulean"}, {"contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "a.kuzniar", "collection": "person"}, "isContactPerson": true}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "f.zapata", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "v.maccatrozzo", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "e.ranguelova", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "l.bogaardt", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "h.spreeuw", "collection": "person"}, "isContactPerson": false}], "createdAt": "2018-11-09T11:22:48Z", "createdBy": "arnikz", "getStartedURL": "https://github.com/EOSC-LOFAR/lofar-ld/blob/master/README.md", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "e741f88d-adf8-4c0b-8ef4-b61ba2d4e29a", "collection": "software"}, "programmingLanguage": ["SPARQL", "SQL", "Python", "Shell scripts"], "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "astron", "collection": "organization"}}, {"foreignKey": {"id": "surfsara", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "eoscpilot-lofar", "collection": "project"}}], "software": [{"foreignKey": {"id": "fairdatapoint", "collection": "software"}}, {"foreignKey": {"id": "linked-data-platform-for-plant-breeding-genomics", "collection": "software"}}]}, "repositoryURLs": {"github": ["https://github.com/EOSC-LOFAR/lofar-ld"]}, "shortStatement": "Publish LOFAR catalog as Linked Data.", "tags": ["Inter-operability & linked data"], "testimonials": [], "updatedAt": "2019-02-21T15:07:14Z", "updatedBy": "arnikz", "brandName": "lofar-ld", "conceptDOI": "10.5281/zenodo.1481766", "bullets": "- exposes LOFAR Long Term Archive catalog (medata) through SPARQL and FAIR Data Point APIs\n- uses domain-specific ontologies and controlled vocabularies for astronomy-related concepts", "slug": "lofar-linked-data-platform"}, {"brandName": "OpenDA", "bullets": "* Provides researchers with a tool for experimentation with data-assimilation/calibration methods without the need for extensive programming\n* Enables quick implementation of data-assimilation and calibration for arbitrary numerical models\n* No need to learn and implement many different Data Assimilation and calibration algorithms/methods\n* Successfully used in many applications and publications: e.g., eWaterCycle I & II, OpenFOAM, Clever Monitoring.\n", "conceptDOI": "10.0000/FIXME", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "n.drost", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "19fd8a01-01de-4283-b38e-e0faad8f92f6", "collection": "organization"}}], "foreignKey": {"id": "5c3d65f5-57c1-4920-91b8-d012c739afe0", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "deltares", "collection": "organization"}}], "foreignKey": {"id": "c72837e8-a1ed-4135-98c0-701ab3470647", "collection": "person"}, "isContactPerson": false}, {"affiliations": [{"foreignKey": {"id": "19fd8a01-01de-4283-b38e-e0faad8f92f6", "collection": "organization"}}], "foreignKey": {"id": "e2b2aa12-f8e8-4dd1-adac-364cb57fd2a9", "collection": "person"}, "isContactPerson": false}], "createdAt": "2019-01-29T10:57:47Z", "createdBy": "yifatdzigan", "getStartedURL": "http://www.openda.org/index.php/documentation", "isFeatured": false, "isPublished": true, "license": ["LGPL-3.0"], "primaryKey": {"id": "1d51052b-5149-451e-b15a-607f05fcc13f", "collection": "software"}, "programmingLanguage": ["C", "C++", "Java", "Fortran"], "readMore": "OpenDA is an open interface standard for (and free implementation of) a set of tools to quickly implement data-assimilation and calibration for arbitrary numerical models. OpenDA wants to stimulate the use of data-assimilation and calibration by lowering the implementation costs and enhancing the exchange of software among researchers and end-users.\nA model that conforms to the OpenDA standard can use all the tools that are available in OpenDA. This allows experimentation with data-assimilation/calibration methods without the need for extensive programming. Reversely, developers of data-assimilation/calibration software that make their implementations compatible with the OpenDA interface will make their new methods usable for all OpenDA users (either for free or on a commercial basis).\nOpenDA has been designed for high performance. Hence, even large-scale models can use it. Also, OpenDA allows users to optimize the interaction between their model and the data-assimilation/calibration methods. Hence, data-assimilation with OpenDA can be as efficient as with custom-made implementations of data-assimilation methods.\n", "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "deltares", "collection": "organization"}}, {"foreignKey": {"id": "tudelft", "collection": "organization"}}, {"foreignKey": {"id": "19fd8a01-01de-4283-b38e-e0faad8f92f6", "collection": "organization"}}, {"foreignKey": {"id": "5d3e06cf-02b5-433f-a5ab-af0a646e8b3a", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "ewatercycle-ii", "collection": "project"}}, {"foreignKey": {"id": "ewatercycle", "collection": "project"}}, {"foreignKey": {"id": "large-scale-data-assimilation", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/OpenDA-Association/OpenDA"]}, "shortStatement": "Open data assimilation toolbox. OpenDA is an open interface standard for a set of tools to quickly implement data-assimilation and calibration for arbitrary numerical models.", "tags": ["Optimized data handling"], "testimonials": [], "updatedAt": "2019-02-06T12:56:04Z", "updatedBy": "yifatdzigan", "slug": "openda"}, {"brandName": "WRFpy", "bullets": "* Provides a simple user-editable JSON configuration file\n* Integrates with the Cylc workflow engine to access distributed computing and storage resources as well as monitoring\n* Supports data assimilation through WRFDA and postprocessing through NCEP Unified Post Processing System (UPP)", "conceptDOI": "10.5281/zenodo.1420918", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "r.vanharen", "collection": "person"}, "isContactPerson": true}], "createdAt": "2019-03-20T10:52:51Z", "createdBy": "rvanharen", "getStartedURL": "https://github.com/era-urban/wrfpy", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "4107163f-5ac9-4c47-a39d-b7f4aa4cf374", "collection": "software"}, "programmingLanguage": ["Python"], "readMore": "WRFpy is a python application that provides an easy way to set up, run, and monitor (long) Weather Research and Forecasting (WRF) simulations. It provides a simple user-editable JSON configuration file and integrates with Cylc to access distributed computing and storage resources as well as monitoring. Optionally, WRFpy allows for data assimilation using WRF data assimilation system (WRFDA) and postprocessing of wrfinput files using the NCEP Unified Post Processing System (UPP).", "related": {"mentions": [{"foreignKey": {"id": "ZCLCLUF3", "collection": "mention"}}, {"foreignKey": {"id": "FEJ3YZZR", "collection": "mention"}}, {"foreignKey": {"id": "EBCQNERQ", "collection": "mention"}}, {"foreignKey": {"id": "ICRDZN9G", "collection": "mention"}}], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "wur", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "era-urban", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/era-urban/wrfpy"]}, "shortStatement": "WRFpy is a python application that provides an easy way to set up, run, and monitor Weather Research and Forecasting simulations", "tags": [], "testimonials": [], "updatedAt": "2019-03-20T12:45:19Z", "updatedBy": "rvanharen", "slug": "wrfpy"}, {"brandName": "NetCDF2LittleR", "bullets": "* Provides an easy way to convert netCDF files into the LittleR file format", "conceptDOI": "10.5281/zenodo.1288465", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "r.vanharen", "collection": "person"}, "isContactPerson": true}], "createdAt": "2019-03-20T12:33:44Z", "createdBy": "rvanharen", "getStartedURL": "https://github.com/ERA-URBAN/netcdf2littler", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "fa01eb1d-a38c-408c-872e-84ee29fb575b", "collection": "software"}, "programmingLanguage": ["Fortran"], "readMore": "NetCDF2LittleR is an application to convert NetCDF files to the Little-R format. The Little-R format is the accepted input format for the WRF data assimilation system (WRFDA) preprocessor (obsproc). Currently only the conversion of synoptical weather stations are supported by this application.", "related": {"mentions": [], "organizations": [], "projects": [{"foreignKey": {"id": "era-urban", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/ERA-URBAN/netcdf2littler"]}, "shortStatement": "An application to convert NetCDF files to the Little-R format", "tags": [], "testimonials": [], "updatedAt": "2019-03-20T12:33:44Z", "updatedBy": "rvanharen", "slug": "netcdf2littler"}, {"brandName": "fm128-radar", "bullets": "* Provides a library to write ascii based fm128_radar radar files to be used in WRFDA\n* Example for KNMI radar data available at https://github.com/ERA-URBAN/fm128_radar_knmi", "conceptDOI": "10.5281/zenodo.1420223", "contributors": [{"affiliations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}], "foreignKey": {"id": "r.vanharen", "collection": "person"}, "isContactPerson": true}], "createdAt": "2019-03-20T12:39:22Z", "createdBy": "rvanharen", "getStartedURL": "https://github.com/ERA-URBAN/fm128_radar", "isFeatured": false, "isPublished": true, "license": ["Apache-2.0"], "primaryKey": {"id": "2228ecf2-351c-4478-a462-6c84e15e790f", "collection": "software"}, "programmingLanguage": ["Python"], "readMore": "fm128-radar provides a python library to write ascii based fm128_radar files to be used in WRFDA. Ascii based fm128_radar files is the only accepted file format for data assimilation of radar data through WRFDA.", "related": {"mentions": [], "organizations": [{"foreignKey": {"id": "nlesc", "collection": "organization"}}, {"foreignKey": {"id": "wur", "collection": "organization"}}], "projects": [{"foreignKey": {"id": "era-urban", "collection": "project"}}], "software": []}, "repositoryURLs": {"github": ["https://github.com/ERA-URBAN/fm128_radar"]}, "shortStatement": "A python library to write ascii based fm128_radar files to be used in WRFDA", "tags": [], "testimonials": [], "updatedAt": "2019-03-20T12:40:22Z", "updatedBy": "rvanharen", "slug": "fm128-radar"}]